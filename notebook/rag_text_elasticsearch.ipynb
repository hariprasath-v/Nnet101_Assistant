{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About\n",
    "### Build an LLM-powered RAG using Elasticsearch ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install OpenAI -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install elasticsearch -qq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade ipywidgets -qq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import json\n",
    "import elasticsearch\n",
    "from elasticsearch import Elasticsearch\n",
    "from tqdm.notebook import tqdm, tqdm_notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>q_link</th>\n",
       "      <th>tags</th>\n",
       "      <th>q_question_id</th>\n",
       "      <th>q_is_answered</th>\n",
       "      <th>q_accepted_answer_id</th>\n",
       "      <th>q_view_count</th>\n",
       "      <th>q_answer_count</th>\n",
       "      <th>q_score</th>\n",
       "      <th>q_last_activity_date</th>\n",
       "      <th>q_creation_date</th>\n",
       "      <th>a_score</th>\n",
       "      <th>a_creation_date</th>\n",
       "      <th>a_answer</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to choose the number of hidden layers and ...</td>\n",
       "      <td>https://stats.stackexchange.com/questions/181/...</td>\n",
       "      <td>model-selection|neural-networks</td>\n",
       "      <td>181</td>\n",
       "      <td>True</td>\n",
       "      <td>1097</td>\n",
       "      <td>1145801</td>\n",
       "      <td>10</td>\n",
       "      <td>820</td>\n",
       "      <td>1661947755</td>\n",
       "      <td>1279584902</td>\n",
       "      <td>671</td>\n",
       "      <td>1280715630</td>\n",
       "      <td>I realize this question has been answered, but...</td>\n",
       "      <td>**Network Configuration in Neural Networks**\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What should I do when my neural network doesn&amp;...</td>\n",
       "      <td>https://stats.stackexchange.com/questions/3520...</td>\n",
       "      <td>neural-networks|faq</td>\n",
       "      <td>352036</td>\n",
       "      <td>True</td>\n",
       "      <td>352037</td>\n",
       "      <td>365434</td>\n",
       "      <td>9</td>\n",
       "      <td>368</td>\n",
       "      <td>1701358003</td>\n",
       "      <td>1529367960</td>\n",
       "      <td>455</td>\n",
       "      <td>1529367960</td>\n",
       "      <td>1.  Verify that your code is bug free\\nThere's...</td>\n",
       "      <td>**Key Considerations for Neural Network Develo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What exactly are keys, queries, and values in ...</td>\n",
       "      <td>https://stats.stackexchange.com/questions/4219...</td>\n",
       "      <td>neural-networks|natural-language|attention|mac...</td>\n",
       "      <td>421935</td>\n",
       "      <td>True</td>\n",
       "      <td>424127</td>\n",
       "      <td>261109</td>\n",
       "      <td>11</td>\n",
       "      <td>309</td>\n",
       "      <td>1708928023</td>\n",
       "      <td>1565686855</td>\n",
       "      <td>281</td>\n",
       "      <td>1567068576</td>\n",
       "      <td>The key/value/query formulation of attention i...</td>\n",
       "      <td>In the key/value/query formulation of attentio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is batch size in neural network?</td>\n",
       "      <td>https://stats.stackexchange.com/questions/1535...</td>\n",
       "      <td>neural-networks|python|terminology|keras</td>\n",
       "      <td>153531</td>\n",
       "      <td>True</td>\n",
       "      <td>153535</td>\n",
       "      <td>731148</td>\n",
       "      <td>6</td>\n",
       "      <td>305</td>\n",
       "      <td>1650529048</td>\n",
       "      <td>1432286121</td>\n",
       "      <td>421</td>\n",
       "      <td>1432288067</td>\n",
       "      <td>The batch size defines the number of samples t...</td>\n",
       "      <td>**Summary**\\n\\n**Batch Size**\\n\\nBatch size de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the advantages of ReLU over sigmoid f...</td>\n",
       "      <td>https://stats.stackexchange.com/questions/1262...</td>\n",
       "      <td>machine-learning|neural-networks|sigmoid-curve...</td>\n",
       "      <td>126238</td>\n",
       "      <td>True</td>\n",
       "      <td>126362</td>\n",
       "      <td>290897</td>\n",
       "      <td>9</td>\n",
       "      <td>234</td>\n",
       "      <td>1723495231</td>\n",
       "      <td>1417486429</td>\n",
       "      <td>205</td>\n",
       "      <td>1417567286</td>\n",
       "      <td>Two additional major benefits of ReLUs are spa...</td>\n",
       "      <td>**Summary:**\\n\\nRectified Linear Units (ReLUs)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  How to choose the number of hidden layers and ...   \n",
       "1  What should I do when my neural network doesn&...   \n",
       "2  What exactly are keys, queries, and values in ...   \n",
       "3              What is batch size in neural network?   \n",
       "4  What are the advantages of ReLU over sigmoid f...   \n",
       "\n",
       "                                              q_link  \\\n",
       "0  https://stats.stackexchange.com/questions/181/...   \n",
       "1  https://stats.stackexchange.com/questions/3520...   \n",
       "2  https://stats.stackexchange.com/questions/4219...   \n",
       "3  https://stats.stackexchange.com/questions/1535...   \n",
       "4  https://stats.stackexchange.com/questions/1262...   \n",
       "\n",
       "                                                tags  q_question_id  \\\n",
       "0                    model-selection|neural-networks            181   \n",
       "1                                neural-networks|faq         352036   \n",
       "2  neural-networks|natural-language|attention|mac...         421935   \n",
       "3           neural-networks|python|terminology|keras         153531   \n",
       "4  machine-learning|neural-networks|sigmoid-curve...         126238   \n",
       "\n",
       "   q_is_answered  q_accepted_answer_id  q_view_count  q_answer_count  q_score  \\\n",
       "0           True                  1097       1145801              10      820   \n",
       "1           True                352037        365434               9      368   \n",
       "2           True                424127        261109              11      309   \n",
       "3           True                153535        731148               6      305   \n",
       "4           True                126362        290897               9      234   \n",
       "\n",
       "   q_last_activity_date  q_creation_date  a_score  a_creation_date  \\\n",
       "0            1661947755       1279584902      671       1280715630   \n",
       "1            1701358003       1529367960      455       1529367960   \n",
       "2            1708928023       1565686855      281       1567068576   \n",
       "3            1650529048       1432286121      421       1432288067   \n",
       "4            1723495231       1417486429      205       1417567286   \n",
       "\n",
       "                                            a_answer  \\\n",
       "0  I realize this question has been answered, but...   \n",
       "1  1.  Verify that your code is bug free\\nThere's...   \n",
       "2  The key/value/query formulation of attention i...   \n",
       "3  The batch size defines the number of samples t...   \n",
       "4  Two additional major benefits of ReLUs are spa...   \n",
       "\n",
       "                                              answer  \n",
       "0  **Network Configuration in Neural Networks**\\n...  \n",
       "1  **Key Considerations for Neural Network Develo...  \n",
       "2  In the key/value/query formulation of attentio...  \n",
       "3  **Summary**\\n\\n**Batch Size**\\n\\nBatch size de...  \n",
       "4  **Summary:**\\n\\nRectified Linear Units (ReLUs)...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'https://raw.githubusercontent.com/hariprasath-v/Nnet101_Assistant/refs/heads/main/data/Stackoverflow_data(neural_networks_stats)_pre_processed_Gemini_LLM.csv'\n",
    "data = pd.read_csv(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = data[['question','tags','answer']].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elasticsearch setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200/', request_timeout=60) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\" : \"048022699c89\",\n",
      "  \"cluster_name\" : \"docker-cluster\",\n",
      "  \"cluster_uuid\" : \"dEW__8ZMTlS1ICK92s7vow\",\n",
      "  \"version\" : {\n",
      "    \"number\" : \"8.4.3\",\n",
      "    \"build_flavor\" : \"default\",\n",
      "    \"build_type\" : \"docker\",\n",
      "    \"build_hash\" : \"42f05b9372a9a4a470db3b52817899b99a76ee73\",\n",
      "    \"build_date\" : \"2022-10-04T07:17:24.662462378Z\",\n",
      "    \"build_snapshot\" : false,\n",
      "    \"lucene_version\" : \"9.3.0\",\n",
      "    \"minimum_wire_compatibility_version\" : \"7.17.0\",\n",
      "    \"minimum_index_compatibility_version\" : \"7.0.0\"\n",
      "  },\n",
      "  \"tagline\" : \"You Know, for Search\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl localhost:9200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and add index to elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'nnet101'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"answer\": {\"type\": \"text\"},\n",
    "            \"tags\": {\"type\": \"keyword\"},\n",
    "            \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"nnet101\"\n",
    "\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fcd58078cbb46e182f408604147fef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm_notebook(data_dict):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elasticsearch query parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^3\", \"answer\", \"tags\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "    \n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'What is global max pooling layer and what is its advantage over maxpooling layer?',\n",
       "  'tags': 'neural-networks|convolutional-neural-network|pooling',\n",
       "  'answer': '**Summary:**\\n\\nGlobal max pooling is a type of max pooling where the pool size is equal to the input size. Unlike regular max pooling, which produces a smaller output, global max pooling produces an output with the same dimensionality as the input.\\n\\nIn global max pooling, the maximum value across the entire input is extracted, providing a representation that focuses on the most prominent feature. This is useful in applications like natural language processing, where the most important words in a sentence are often indicative of its meaning.\\n\\nIn contrast, regular max pooling divides the input into smaller segments and extracts the maximum value from each segment, reducing the output size. This is more common in computer vision, where spatial information is important and reducing the size of the representation can be beneficial for computational efficiency.'},\n",
       " {'question': 'Feature extracted by max pooling vs mean pooling',\n",
       "  'tags': 'machine-learning|deep-learning|feature-engineering|computer-vision',\n",
       "  'answer': 'Convolutional layers extract features from input data, while pooling layers compress these features to reduce dimensionality. There are two main types of pooling layers: max-pooling and mean-pooling.\\n\\n**Max-pooling** selects the maximum activation value within a block of data, prioritizing the presence of a specific feature in a general area. However, it can lose information about low activations within that block.\\n\\n**Mean-pooling** calculates the average activation value within a block, which can smooth out large activations. It retains some information about low activations but may not capture the presence of specific features as strongly as max-pooling.\\n\\nThe choice between max-pooling and mean-pooling depends on the desired level of feature extraction and the importance of preserving low activation information.'},\n",
       " {'question': 'Why is max pooling necessary in convolutional neural networks?',\n",
       "  'tags': 'deep-learning|convolutional-neural-network|pooling',\n",
       "  'answer': '**Summary:**\\n\\nPooling layers in convolutional neural networks (CNNs) offer some translation invariance and computational efficiency. However, they can be replaced by convolutions with stride, which may yield superior results.\\n\\nSome recent CNN architectures, such as Wide Residual Networks and DenseNets, employ average pooling. Others, like DelugeNets, utilize convolutions with stride. The optimal choice between pooling and convolutions can vary depending on the network architecture and task.\\n\\nOverall, the use of convolutions with stride can be a viable alternative to pooling layers in CNNs, offering the potential for enhanced performance.'},\n",
       " {'question': 'What is an embedding layer in a neural network?',\n",
       "  'tags': 'machine-learning|neural-networks|python|word-embeddings',\n",
       "  'answer': '**Relation to Word2Vec:**\\nWord2Vec embodies words as vectors in a continuous space, allowing for similarity comparisons based on vector distance. This enables the distributed representation of n-grams and the analysis of semantic relationships.\\n\\n**Lasagne Code Explanation:**\\nThe code snippet demonstrates the use of Lasagne to create a word embedding layer. The vocabulary size is defined as 3, and each word is embedded as a 5-dimensional vector. The word embedding matrix is initialized with values from 0 to 14.\\n\\nThe data is then represented as 2-grams in a sparse matrix format, where each row represents a 2-gram. The embedding function is applied to these 2-grams, resulting in a matrix that represents each 2-gram as a pair of 5-dimensional vectors. The dimensions of the output matrix are consistent with the vocabulary size and embedding size specified in the code.'},\n",
       " {'question': 'Difference between pooling and subsampling',\n",
       "  'tags': 'neural-networks|convolutional-neural-network|computer-vision',\n",
       "  'answer': '**Summary:**\\n\\nPooling layers in convolutional neural networks (CNNs) perform a form of subsampling that reduces the dimensionality of the input data. This process of reducing the size of the data while retaining its essential features is known as subsampling.\\n\\nThe paper \"Gradient-Based Learning Applied to Document Recognition\" by Yann LeCun refers to subsampling as a pooling layer. This suggests that pooling layers can be used to perform subsampling operations in CNNs.\\n\\nIn essence, pooling operations are a type of subsampling that reduce the size of the image while preserving its important characteristics. This makes them a crucial component in CNNs for efficiently extracting features from images.'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_search(\n",
    "    query=\"What is pooling layer?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ollamaâ€™s OpenAI compatible API endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1',\n",
    "    api_key='ollama',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to a create prompt using retrieved results and user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"tags: {doc['tags']}\\nquestion: {doc['question']}\\nanswer: {doc['answer']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gemma:2b\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG\n",
    "#### The function retrieves elasticsearch results based on the user's query, creates a prompt using those results, and feeds it into the LLM to generate the final response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = elastic_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A pooling layer is a type of neural network layer that reduces the dimensionality of a feature map by performing a mathematical operation (such as averaging, max-pooling, or min-pooling) on the original feature map.\n",
      "\n",
      "**Key features of pooling layers:**\n",
      "\n",
      "* **Perform dimensionality reduction:** By taking a smaller subset of features from the original feature map, pooling layers reduce the model's complexity and improve performance.\n",
      "* **Reduce computation time:** While reducing dimensionality, pooling layers can also perform computation more efficiently by reducing the amount of matrix multiplication required.\n",
      "* **Adapt to different data types:** Pooling can be applied to both 1D and 2D feature maps, making it useful for tasks such as image classification, object detection, and semantic segmentation.\n",
      "* **Improve feature distribution:** Pooling can help to spread out feature values, reducing their concentration in certain areas of the feature map.\n",
      "\n",
      "**Types of pooling layers:**\n",
      "\n",
      "* **Average pooling:** Calculates the average value of the features in a given window size.\n",
      "* **Max pooling:** Takes the maximum value from the features in a given window size.\n",
      "* **Min pooling:** Takes the minimum value from the features in a given window size.\n",
      "* **Max-average pooling:** Performs max pooling followed by average pooling on the feature map.\n",
      "* **Average-max pooling:** Uses the average of the maximum values in a given window size.\n",
      "* **Spatial attention pooling:** Focuses on certain areas of the feature map based on their importance.\n",
      "\n",
      "**Applications of pooling layers:**\n",
      "\n",
      "* Feature extraction: Pooling layers are often used to extract meaningful features from input data before feeding it into subsequent layers in the neural network.\n",
      "* Dimensionality reduction: By reducing the dimensionality of feature maps, pooling layers can improve models' ability to learn complex relationships between features.\n",
      "* Object detection: Pooling layers are commonly used in object detection models to extract relevant features from images.\n",
      "* Image segmentation: Pooling layers can be used to group and segment similar pixels in an image.\n",
      "* Text classification: Pooling layers can be used to fuse features from different text documents.\n",
      "CPU times: user 9.2 ms, sys: 2.32 ms, total: 11.5 ms\n",
      "Wall time: 41.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(llm('what is pooling layer?'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
