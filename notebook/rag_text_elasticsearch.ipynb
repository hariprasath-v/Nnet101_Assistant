{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About\n",
    "### Build an LLM-powered RAG using Elasticsearch ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install OpenAI -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install elasticsearch -qq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade ipywidgets -qq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import json\n",
    "import elasticsearch\n",
    "from elasticsearch import Elasticsearch\n",
    "from tqdm.notebook import tqdm, tqdm_notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_title</th>\n",
       "      <th>q_link</th>\n",
       "      <th>q_tags</th>\n",
       "      <th>q_question_id</th>\n",
       "      <th>q_is_answered</th>\n",
       "      <th>q_accepted_answer_id</th>\n",
       "      <th>q_view_count</th>\n",
       "      <th>q_answer_count</th>\n",
       "      <th>q_score</th>\n",
       "      <th>q_last_activity_date</th>\n",
       "      <th>q_creation_date</th>\n",
       "      <th>a_score</th>\n",
       "      <th>a_creation_date</th>\n",
       "      <th>a_answer</th>\n",
       "      <th>llm_answer_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to choose the number of hidden layers and ...</td>\n",
       "      <td>https://stats.stackexchange.com/questions/181/...</td>\n",
       "      <td>['model-selection', 'neural-networks']</td>\n",
       "      <td>181</td>\n",
       "      <td>True</td>\n",
       "      <td>1097</td>\n",
       "      <td>1145532</td>\n",
       "      <td>10</td>\n",
       "      <td>820</td>\n",
       "      <td>1661947755</td>\n",
       "      <td>1279584902</td>\n",
       "      <td>671</td>\n",
       "      <td>1280715630</td>\n",
       "      <td>I realize this question has been answered, but...</td>\n",
       "      <td>**Network Configuration in Neural Networks**\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What should I do when my neural network doesn&amp;...</td>\n",
       "      <td>https://stats.stackexchange.com/questions/3520...</td>\n",
       "      <td>['neural-networks', 'faq']</td>\n",
       "      <td>352036</td>\n",
       "      <td>True</td>\n",
       "      <td>352037</td>\n",
       "      <td>365347</td>\n",
       "      <td>9</td>\n",
       "      <td>368</td>\n",
       "      <td>1701358003</td>\n",
       "      <td>1529367960</td>\n",
       "      <td>455</td>\n",
       "      <td>1529367960</td>\n",
       "      <td>1.  Verify that your code is bug free\\nThere's...</td>\n",
       "      <td>**Summary:**\\n\\nBuilding neural networks requi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What exactly are keys, queries, and values in ...</td>\n",
       "      <td>https://stats.stackexchange.com/questions/4219...</td>\n",
       "      <td>['neural-networks', 'natural-language', 'atten...</td>\n",
       "      <td>421935</td>\n",
       "      <td>True</td>\n",
       "      <td>424127</td>\n",
       "      <td>260772</td>\n",
       "      <td>11</td>\n",
       "      <td>309</td>\n",
       "      <td>1708928023</td>\n",
       "      <td>1565686855</td>\n",
       "      <td>281</td>\n",
       "      <td>1567068576</td>\n",
       "      <td>The key/value/query formulation of attention i...</td>\n",
       "      <td>Attention is a retrieval process that involves...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is batch size in neural network?</td>\n",
       "      <td>https://stats.stackexchange.com/questions/1535...</td>\n",
       "      <td>['neural-networks', 'python', 'terminology', '...</td>\n",
       "      <td>153531</td>\n",
       "      <td>True</td>\n",
       "      <td>153535</td>\n",
       "      <td>730947</td>\n",
       "      <td>6</td>\n",
       "      <td>305</td>\n",
       "      <td>1650529048</td>\n",
       "      <td>1432286121</td>\n",
       "      <td>421</td>\n",
       "      <td>1432288067</td>\n",
       "      <td>The batch size defines the number of samples t...</td>\n",
       "      <td>**Batch Size: Optimization in Deep Learning**\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the advantages of ReLU over sigmoid f...</td>\n",
       "      <td>https://stats.stackexchange.com/questions/1262...</td>\n",
       "      <td>['machine-learning', 'neural-networks', 'sigmo...</td>\n",
       "      <td>126238</td>\n",
       "      <td>True</td>\n",
       "      <td>126362</td>\n",
       "      <td>290838</td>\n",
       "      <td>9</td>\n",
       "      <td>234</td>\n",
       "      <td>1723495231</td>\n",
       "      <td>1417486429</td>\n",
       "      <td>205</td>\n",
       "      <td>1417567286</td>\n",
       "      <td>Two additional major benefits of ReLUs are spa...</td>\n",
       "      <td>ReLU (Rectified Linear Unit) functions, define...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             q_title  \\\n",
       "0  How to choose the number of hidden layers and ...   \n",
       "1  What should I do when my neural network doesn&...   \n",
       "2  What exactly are keys, queries, and values in ...   \n",
       "3              What is batch size in neural network?   \n",
       "4  What are the advantages of ReLU over sigmoid f...   \n",
       "\n",
       "                                              q_link  \\\n",
       "0  https://stats.stackexchange.com/questions/181/...   \n",
       "1  https://stats.stackexchange.com/questions/3520...   \n",
       "2  https://stats.stackexchange.com/questions/4219...   \n",
       "3  https://stats.stackexchange.com/questions/1535...   \n",
       "4  https://stats.stackexchange.com/questions/1262...   \n",
       "\n",
       "                                              q_tags  q_question_id  \\\n",
       "0             ['model-selection', 'neural-networks']            181   \n",
       "1                         ['neural-networks', 'faq']         352036   \n",
       "2  ['neural-networks', 'natural-language', 'atten...         421935   \n",
       "3  ['neural-networks', 'python', 'terminology', '...         153531   \n",
       "4  ['machine-learning', 'neural-networks', 'sigmo...         126238   \n",
       "\n",
       "   q_is_answered  q_accepted_answer_id  q_view_count  q_answer_count  q_score  \\\n",
       "0           True                  1097       1145532              10      820   \n",
       "1           True                352037        365347               9      368   \n",
       "2           True                424127        260772              11      309   \n",
       "3           True                153535        730947               6      305   \n",
       "4           True                126362        290838               9      234   \n",
       "\n",
       "   q_last_activity_date  q_creation_date  a_score  a_creation_date  \\\n",
       "0            1661947755       1279584902      671       1280715630   \n",
       "1            1701358003       1529367960      455       1529367960   \n",
       "2            1708928023       1565686855      281       1567068576   \n",
       "3            1650529048       1432286121      421       1432288067   \n",
       "4            1723495231       1417486429      205       1417567286   \n",
       "\n",
       "                                            a_answer  \\\n",
       "0  I realize this question has been answered, but...   \n",
       "1  1.  Verify that your code is bug free\\nThere's...   \n",
       "2  The key/value/query formulation of attention i...   \n",
       "3  The batch size defines the number of samples t...   \n",
       "4  Two additional major benefits of ReLUs are spa...   \n",
       "\n",
       "                                  llm_answer_summary  \n",
       "0  **Network Configuration in Neural Networks**\\n...  \n",
       "1  **Summary:**\\n\\nBuilding neural networks requi...  \n",
       "2  Attention is a retrieval process that involves...  \n",
       "3  **Batch Size: Optimization in Deep Learning**\\...  \n",
       "4  ReLU (Rectified Linear Unit) functions, define...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'https://raw.githubusercontent.com/hariprasath-v/Nnet101_Assistant/refs/heads/main/data/Stackoverflow_data(neural_networks_stats)_pre_processed_Gemini_LLM.csv'\n",
    "data = pd.read_csv(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing\n",
    "#### combine tags with pipe operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model-selection', 'neural-networks']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast.literal_eval(data['q_tags'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['q_tags'] = data['q_tags'].apply(lambda x: \"|\".join(i.strip() for i in ast.literal_eval(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = data[['q_title','q_tags','llm_answer_summary']].rename(columns={'q_title':'question','q_tags':'tags','llm_answer_summary':'answer'}).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elasticsearch setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200/', request_timeout=60) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\" : \"4da7f4364af6\",\n",
      "  \"cluster_name\" : \"docker-cluster\",\n",
      "  \"cluster_uuid\" : \"KEosNzKHRpCSdDQkICVeNA\",\n",
      "  \"version\" : {\n",
      "    \"number\" : \"8.4.3\",\n",
      "    \"build_flavor\" : \"default\",\n",
      "    \"build_type\" : \"docker\",\n",
      "    \"build_hash\" : \"42f05b9372a9a4a470db3b52817899b99a76ee73\",\n",
      "    \"build_date\" : \"2022-10-04T07:17:24.662462378Z\",\n",
      "    \"build_snapshot\" : false,\n",
      "    \"lucene_version\" : \"9.3.0\",\n",
      "    \"minimum_wire_compatibility_version\" : \"7.17.0\",\n",
      "    \"minimum_index_compatibility_version\" : \"7.0.0\"\n",
      "  },\n",
      "  \"tagline\" : \"You Know, for Search\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl localhost:9200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and add index to elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'nnet101'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"answer\": {\"type\": \"text\"},\n",
    "            \"tags\": {\"type\": \"keyword\"},\n",
    "            \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"nnet101\"\n",
    "\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf0637361b774937806e2e27c20f8c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm_notebook(data_1):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elasticsearch query parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^3\", \"answer\", \"tags\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "    \n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'What is global max pooling layer and what is its advantage over maxpooling layer?',\n",
       "  'tags': 'neural-networks|conv-neural-network|pooling',\n",
       "  'answer': \"Global max pooling is a max pooling operation where the pool size equals the input size. It outputs the maximum value for each feature across the input's temporal dimension. Ordinary max pooling, in contrast, takes a specified pool size and outputs maximum values within that window.\\n\\nIn Keras, the `GlobalMaxPooling1D` layer performs global max pooling on 1D temporal data. It converts a 3D tensor (samples, steps, features) to a 2D tensor (samples, features).\\n\\nGlobal max pooling is commonly used in domains like natural language processing, while ordinary max pooling is more prevalent in domains like computer vision.\"},\n",
       " {'question': 'What is an embedding layer in a neural network?',\n",
       "  'tags': 'machine-learning|neural-networks|python|word-embeddings',\n",
       "  'answer': 'Word2Vec, a natural language processing technique, represents vocabulary as continuous vectors, allowing for semantic similarity evaluation. By using a continuous word embedding map, similar words are mapped to similar vector regions.\\n\\nIn the provided example, Lasagne code demonstrates the process of word embedding using a 3x5 matrix W. This matrix maps the three vocabulary words ($w_0, w_1, w_2$) to a 5-dimensional vector space. The example considers 2-grams, such as (w0, w2), and shows the embedding result as a matrix multiplication between the sparse 2-gram encoding and the word embedding matrix.\\n\\nBy embedding n-grams into a continuous vector space, this Word2Vec approach enables the application of continuous similarity metrics to assess the semantic quality of these representations. It allows for more accurate evaluation of word and n-gram relationships, leading to improved natural language processing tasks.'},\n",
       " {'question': 'Why is max pooling necessary in convolutional neural networks?',\n",
       "  'tags': 'deep-learning|conv-neural-network|pooling',\n",
       "  'answer': \"**Summary:**\\n\\nPooling layers, while providing translation invariance and computational speed, may not always be optimal.\\n\\nRecent research suggests that replacing pooling with convolutional layers with stride can improve performance. Experiments have shown success with average pooling (in Wide Residual Networks and DenseNets) and convolutional stride (in DelugeNets).\\n\\nThis strategy eliminates pooling's drawbacks while maintaining its benefits, allowing for more efficient and accurate convolution-based neural networks.\"},\n",
       " {'question': 'What does the hidden layer in a neural network compute?',\n",
       "  'tags': 'machine-learning|neural-networks|nonlinear-regression',\n",
       "  'answer': \"Feed-forward neural networks apply functions to transform data sequentially. Each layer performs a linear transformation followed by a non-linearity. The hidden layers modify inputs to assist the output layer in generating the desired output. The functions used vary depending on the network, but commonly include logical operators or image processing functions.\\n\\nEach layer's role is determined by the functions it computes. The output of a layer is the result of applying multiple functions to the input. This allows networks to represent complex relationships that cannot be expressed by a single function.\\n\\nIn practical applications, hidden layers are designed to detect specific features in data (e.g., edges in images). These features are then combined by subsequent layers to form more complex representations (e.g., eyes in an image). This hierarchical approach makes it easier to identify high-level patterns and perform complex tasks.\"},\n",
       " {'question': 'Which activation function for output layer?',\n",
       "  'tags': 'neural-networks',\n",
       "  'answer': 'In regression tasks, where the output range is unbounded, a linear activation function is recommended. For classification tasks, a softmax activation function is often preferred, as it ensures the output represents a probability distribution. However, in scenarios where multiple classes can be true simultaneously (e.g., image object detection), a simple sigmoid activation function may be sufficient, allowing outputs that do not sum to one and represent the presence or absence of multiple objects.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_search(\n",
    "    query=\"What is pooling layer?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ollama’s OpenAI compatible API endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1',\n",
    "    api_key='ollama',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to a create prompt using retrieved results and user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"tags: {doc['tags']}\\nquestion: {doc['question']}\\nanswer: {doc['answer']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gemma:2b\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG\n",
    "#### The function retrieves elasticsearch results based on the user's query, creates a prompt using those results, and feeds it into the LLM to generate the final response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = elastic_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure. Here's the definition of the pooling layer:\n",
      "\n",
      "**Pooling Layer**\n",
      "\n",
      "A pooling layer is a type of neural network layer used in computer vision and natural language processing (NLP) to reduce the dimensionality of data while preserving important features. It achieves this by taking multiple smaller feature maps and combining them into a single larger map. This technique helps to reduce computational costs and improve model performance.\n",
      "\n",
      "**Key Characteristics of Pooling Layers:**\n",
      "\n",
      "* **Input:** Pooling layers take multiple input feature maps of equal size as their input.\n",
      "* **Output:** The output is a single feature map with the same dimensions as the input.\n",
      "* **Method:** There are different pooling methods, such as max pooling, average pooling, and max-pooling with a kernel size of 2x2.\n",
      "* **Regularization:** Pooling layers can be followed by a regularizer layer to prevent overfitting.\n",
      "\n",
      "**How Pooling Layers Work:**\n",
      "\n",
      "Pooling layers work by taking the average or maximum value of each pixel in the input feature map and storing it in the output map. The kernel used for pooling can move over the input map, and multiple feature maps can be pooled together into a single output map. This process effectively reduces the number of parameters needed to represent the data and performs feature extraction.\n",
      "\n",
      "**Benefits of Pooling Layers:**\n",
      "\n",
      "* **Reduced computational costs:** Pooling layers can significantly reduce the number of parameters to be learned, which can lead to faster training and improved model performance.\n",
      "* **Feature preservation:** By combining features into a single map, pooling layers help to preserve important features and reduce noise.\n",
      "* **Improved generalization:** Pooling layers can improve the generalization performance of models by reducing overfitting.\n",
      "\n",
      "**Applications of Pooling Layers:**\n",
      "\n",
      "Pooling layers are commonly used in various computer vision and NLP tasks, including:\n",
      "\n",
      "* Object detection\n",
      "* Image segmentation\n",
      "* Natural language processing\n",
      "* Video analysis\n",
      "\n",
      "**Note:** Pooling layers can be used at various stages in a deep neural network, such as after convolution layers, before fully connected layers.\n",
      "CPU times: user 11.6 ms, sys: 362 μs, total: 12 ms\n",
      "Wall time: 49.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(llm('what is pooling layer?'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
