{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About\n",
    "### Build an LLM-powered RAG using a simple TF-IDF similarity search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install OpenAI -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_title</th>\n",
       "      <th>q_link</th>\n",
       "      <th>q_tags</th>\n",
       "      <th>q_question_id</th>\n",
       "      <th>q_is_answered</th>\n",
       "      <th>q_accepted_answer_id</th>\n",
       "      <th>q_view_count</th>\n",
       "      <th>q_answer_count</th>\n",
       "      <th>q_score</th>\n",
       "      <th>q_last_activity_date</th>\n",
       "      <th>q_creation_date</th>\n",
       "      <th>a_score</th>\n",
       "      <th>a_creation_date</th>\n",
       "      <th>a_answer</th>\n",
       "      <th>llm_answer_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to choose the number of hidden layers and ...</td>\n",
       "      <td>https://stats.stackexchange.com/questions/181/...</td>\n",
       "      <td>['model-selection', 'neural-networks']</td>\n",
       "      <td>181</td>\n",
       "      <td>True</td>\n",
       "      <td>1097</td>\n",
       "      <td>1145532</td>\n",
       "      <td>10</td>\n",
       "      <td>820</td>\n",
       "      <td>1661947755</td>\n",
       "      <td>1279584902</td>\n",
       "      <td>671</td>\n",
       "      <td>1280715630</td>\n",
       "      <td>I realize this question has been answered, but...</td>\n",
       "      <td>**Network Configuration in Neural Networks**\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What should I do when my neural network doesn&amp;...</td>\n",
       "      <td>https://stats.stackexchange.com/questions/3520...</td>\n",
       "      <td>['neural-networks', 'faq']</td>\n",
       "      <td>352036</td>\n",
       "      <td>True</td>\n",
       "      <td>352037</td>\n",
       "      <td>365347</td>\n",
       "      <td>9</td>\n",
       "      <td>368</td>\n",
       "      <td>1701358003</td>\n",
       "      <td>1529367960</td>\n",
       "      <td>455</td>\n",
       "      <td>1529367960</td>\n",
       "      <td>1.  Verify that your code is bug free\\nThere's...</td>\n",
       "      <td>**Summary:**\\n\\nBuilding neural networks requi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What exactly are keys, queries, and values in ...</td>\n",
       "      <td>https://stats.stackexchange.com/questions/4219...</td>\n",
       "      <td>['neural-networks', 'natural-language', 'atten...</td>\n",
       "      <td>421935</td>\n",
       "      <td>True</td>\n",
       "      <td>424127</td>\n",
       "      <td>260772</td>\n",
       "      <td>11</td>\n",
       "      <td>309</td>\n",
       "      <td>1708928023</td>\n",
       "      <td>1565686855</td>\n",
       "      <td>281</td>\n",
       "      <td>1567068576</td>\n",
       "      <td>The key/value/query formulation of attention i...</td>\n",
       "      <td>Attention is a retrieval process that involves...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is batch size in neural network?</td>\n",
       "      <td>https://stats.stackexchange.com/questions/1535...</td>\n",
       "      <td>['neural-networks', 'python', 'terminology', '...</td>\n",
       "      <td>153531</td>\n",
       "      <td>True</td>\n",
       "      <td>153535</td>\n",
       "      <td>730947</td>\n",
       "      <td>6</td>\n",
       "      <td>305</td>\n",
       "      <td>1650529048</td>\n",
       "      <td>1432286121</td>\n",
       "      <td>421</td>\n",
       "      <td>1432288067</td>\n",
       "      <td>The batch size defines the number of samples t...</td>\n",
       "      <td>**Batch Size: Optimization in Deep Learning**\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the advantages of ReLU over sigmoid f...</td>\n",
       "      <td>https://stats.stackexchange.com/questions/1262...</td>\n",
       "      <td>['machine-learning', 'neural-networks', 'sigmo...</td>\n",
       "      <td>126238</td>\n",
       "      <td>True</td>\n",
       "      <td>126362</td>\n",
       "      <td>290838</td>\n",
       "      <td>9</td>\n",
       "      <td>234</td>\n",
       "      <td>1723495231</td>\n",
       "      <td>1417486429</td>\n",
       "      <td>205</td>\n",
       "      <td>1417567286</td>\n",
       "      <td>Two additional major benefits of ReLUs are spa...</td>\n",
       "      <td>ReLU (Rectified Linear Unit) functions, define...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             q_title  \\\n",
       "0  How to choose the number of hidden layers and ...   \n",
       "1  What should I do when my neural network doesn&...   \n",
       "2  What exactly are keys, queries, and values in ...   \n",
       "3              What is batch size in neural network?   \n",
       "4  What are the advantages of ReLU over sigmoid f...   \n",
       "\n",
       "                                              q_link  \\\n",
       "0  https://stats.stackexchange.com/questions/181/...   \n",
       "1  https://stats.stackexchange.com/questions/3520...   \n",
       "2  https://stats.stackexchange.com/questions/4219...   \n",
       "3  https://stats.stackexchange.com/questions/1535...   \n",
       "4  https://stats.stackexchange.com/questions/1262...   \n",
       "\n",
       "                                              q_tags  q_question_id  \\\n",
       "0             ['model-selection', 'neural-networks']            181   \n",
       "1                         ['neural-networks', 'faq']         352036   \n",
       "2  ['neural-networks', 'natural-language', 'atten...         421935   \n",
       "3  ['neural-networks', 'python', 'terminology', '...         153531   \n",
       "4  ['machine-learning', 'neural-networks', 'sigmo...         126238   \n",
       "\n",
       "   q_is_answered  q_accepted_answer_id  q_view_count  q_answer_count  q_score  \\\n",
       "0           True                  1097       1145532              10      820   \n",
       "1           True                352037        365347               9      368   \n",
       "2           True                424127        260772              11      309   \n",
       "3           True                153535        730947               6      305   \n",
       "4           True                126362        290838               9      234   \n",
       "\n",
       "   q_last_activity_date  q_creation_date  a_score  a_creation_date  \\\n",
       "0            1661947755       1279584902      671       1280715630   \n",
       "1            1701358003       1529367960      455       1529367960   \n",
       "2            1708928023       1565686855      281       1567068576   \n",
       "3            1650529048       1432286121      421       1432288067   \n",
       "4            1723495231       1417486429      205       1417567286   \n",
       "\n",
       "                                            a_answer  \\\n",
       "0  I realize this question has been answered, but...   \n",
       "1  1.  Verify that your code is bug free\\nThere's...   \n",
       "2  The key/value/query formulation of attention i...   \n",
       "3  The batch size defines the number of samples t...   \n",
       "4  Two additional major benefits of ReLUs are spa...   \n",
       "\n",
       "                                  llm_answer_summary  \n",
       "0  **Network Configuration in Neural Networks**\\n...  \n",
       "1  **Summary:**\\n\\nBuilding neural networks requi...  \n",
       "2  Attention is a retrieval process that involves...  \n",
       "3  **Batch Size: Optimization in Deep Learning**\\...  \n",
       "4  ReLU (Rectified Linear Unit) functions, define...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'https://raw.githubusercontent.com/hariprasath-v/Nnet101_Assistant/refs/heads/main/data/Stackoverflow_data(neural_networks_stats)_pre_processed_Gemini_LLM.csv'\n",
    "data = pd.read_csv(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing\n",
    "#### combine tags with pipe operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model-selection', 'neural-networks']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast.literal_eval(data['q_tags'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['q_tags'] = data['q_tags'].apply(lambda x: \"|\".join(i.strip() for i in ast.literal_eval(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = data[['q_title','q_tags','llm_answer_summary']].rename(columns={'q_title':'question','q_tags':'tags','llm_answer_summary':'answer'}).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get TF-IDF minisearch code from [DataTalks LLM Zoomcamp](https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/minsearch.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-05 06:37:13--  https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3832 (3.7K) [text/plain]\n",
      "Saving to: ‘minsearch.py.1’\n",
      "\n",
      "minsearch.py.1      100%[===================>]   3.74K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-10-05 06:37:13 (31.9 MB/s) - ‘minsearch.py.1’ saved [3832/3832]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!wget https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import minisearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import minsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How to choose the number of hidden layers and nodes in a feedforward neural network?',\n",
       " 'tags': 'model-selection|neural-networks',\n",
       " 'answer': '**Network Configuration in Neural Networks**\\n\\nNeural networks require network configuration, which involves determining the number and types of layers and the number of neurons within each layer.\\n\\n**Standard Method:**\\n\\n* Initialize a competent network architecture using a set of rules that determine the number and size of input, hidden, and output layers.\\n\\n**Optimization:**\\n\\n* Once initialized, the network configuration can be iteratively tuned during training using pruning techniques.\\n* Pruning eliminates unnecessary nodes based on their low weight values.\\n\\n**Layer Configuration:**\\n\\n* Input layer: Number of neurons determined by the number of features in the training data.\\n* Output layer: Number of neurons determined by the model configuration (classifier vs. regressor).\\n* Hidden layers: Typically one hidden layer is sufficient, and its size can be estimated as the mean of the input and output layer sizes.\\n\\n**Optimization Process:**\\n\\n* Initialize with a larger network configuration to allow for pruning.\\n* Apply a pruning algorithm during training to identify and remove redundant nodes.\\n* This two-step optimization approach is commonly used to approach optimal network configuration.'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample TF-IDF search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\",  \"answer\"],\n",
    "    keyword_fields=[\"rag\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.fit(data_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'what is pooling layer?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'What is global max pooling layer and what is its advantage over maxpooling layer?',\n",
       "  'tags': 'neural-networks|conv-neural-network|pooling',\n",
       "  'answer': \"Global max pooling is a max pooling operation where the pool size equals the input size. It outputs the maximum value for each feature across the input's temporal dimension. Ordinary max pooling, in contrast, takes a specified pool size and outputs maximum values within that window.\\n\\nIn Keras, the `GlobalMaxPooling1D` layer performs global max pooling on 1D temporal data. It converts a 3D tensor (samples, steps, features) to a 2D tensor (samples, features).\\n\\nGlobal max pooling is commonly used in domains like natural language processing, while ordinary max pooling is more prevalent in domains like computer vision.\"},\n",
       " {'question': 'Why is max pooling necessary in convolutional neural networks?',\n",
       "  'tags': 'deep-learning|conv-neural-network|pooling',\n",
       "  'answer': \"**Summary:**\\n\\nPooling layers, while providing translation invariance and computational speed, may not always be optimal.\\n\\nRecent research suggests that replacing pooling with convolutional layers with stride can improve performance. Experiments have shown success with average pooling (in Wide Residual Networks and DenseNets) and convolutional stride (in DelugeNets).\\n\\nThis strategy eliminates pooling's drawbacks while maintaining its benefits, allowing for more efficient and accurate convolution-based neural networks.\"},\n",
       " {'question': 'What is an embedding layer in a neural network?',\n",
       "  'tags': 'machine-learning|neural-networks|python|word-embeddings',\n",
       "  'answer': 'Word2Vec, a natural language processing technique, represents vocabulary as continuous vectors, allowing for semantic similarity evaluation. By using a continuous word embedding map, similar words are mapped to similar vector regions.\\n\\nIn the provided example, Lasagne code demonstrates the process of word embedding using a 3x5 matrix W. This matrix maps the three vocabulary words ($w_0, w_1, w_2$) to a 5-dimensional vector space. The example considers 2-grams, such as (w0, w2), and shows the embedding result as a matrix multiplication between the sparse 2-gram encoding and the word embedding matrix.\\n\\nBy embedding n-grams into a continuous vector space, this Word2Vec approach enables the application of continuous similarity metrics to assess the semantic quality of these representations. It allows for more accurate evaluation of word and n-gram relationships, leading to improved natural language processing tasks.'},\n",
       " {'question': 'What does the hidden layer in a neural network compute?',\n",
       "  'tags': 'machine-learning|neural-networks|nonlinear-regression',\n",
       "  'answer': \"Feed-forward neural networks apply functions to transform data sequentially. Each layer performs a linear transformation followed by a non-linearity. The hidden layers modify inputs to assist the output layer in generating the desired output. The functions used vary depending on the network, but commonly include logical operators or image processing functions.\\n\\nEach layer's role is determined by the functions it computes. The output of a layer is the result of applying multiple functions to the input. This allows networks to represent complex relationships that cannot be expressed by a single function.\\n\\nIn practical applications, hidden layers are designed to detect specific features in data (e.g., edges in images). These features are then combined by subsequent layers to form more complex representations (e.g., eyes in an image). This hierarchical approach makes it easier to identify high-level patterns and perform complex tasks.\"},\n",
       " {'question': 'Softmax layer in a neural network',\n",
       "  'tags': 'neural-networks',\n",
       "  'answer': '**Summary:**\\n\\nThe Jacobian matrix captures the gradients of a diagonal layer with respect to its inputs. It is calculated using the Kronecker Delta, yielding:\\n\\n```\\n[J]_{ij} = h_i(δ_{ij} - h_j)\\n```\\n\\nTo obtain the input errors from the output errors, the Jacobian is used to compute the gradient of the inputs:\\n\\n```\\n$[\\\\nabla x]_k = \\\\sum_{i=1} \\\\nabla h_{i,k}\\n```\\n\\nThis gradient calculation simplifies to a matrix-vector multiplication when using the cross-entropy cost model combined with a softmax output layer:\\n\\n```\\n\\\\vec{\\\\sigma_l} = J\\\\vec{\\\\sigma_{l+1}} = \\\\vec{h} - \\\\vec{t}\\n```\\n\\nwhere $\\\\vec{\\\\sigma}$ represents the errors, $\\\\vec{h}$ the softmax output, and $\\\\vec{t}$ the labels. This simplified form enhances numerical stability.'},\n",
       " {'question': 'Which activation function for output layer?',\n",
       "  'tags': 'neural-networks',\n",
       "  'answer': 'In regression tasks, where the output range is unbounded, a linear activation function is recommended. For classification tasks, a softmax activation function is often preferred, as it ensures the output represents a probability distribution. However, in scenarios where multiple classes can be true simultaneously (e.g., image object detection), a simple sigmoid activation function may be sufficient, allowing outputs that do not sum to one and represent the presence or absence of multiple objects.'},\n",
       " {'question': 'What is pre training a neural network?',\n",
       "  'tags': 'neural-networks|pre-training',\n",
       "  'answer': 'Pre-training involves using previously trained network weights as an initialization for a new network performing a different task or using a different dataset. This head start accelerates training by leveraging the knowledge gained from the first network. However, pre-training is effective when the tasks and datasets share commonalities.\\n\\nWhen pre-training, the initial task and dataset may differ from the fine-tuning stage. Despite this, knowledge can still be transferred to new tasks and datasets, particularly when there are similarities. Pre-training is less effective when there is a significant disconnect between the two stages.'},\n",
       " {'question': 'What is a latent space?',\n",
       "  'tags': 'machine-learning|neural-networks|definition',\n",
       "  'answer': 'Latent space is a multi-dimensional representation of an observation space that captures underlying patterns and features not directly observable. It reduces the dimensionality of complex observations, providing a more manageable representation for models to learn from. Latent space aims to encode meaningful internal representations of events, similar to human understanding of various topics.\\n\\nLearning a latent space allows models to make better sense of observed data, as it identifies small variations in latent space that correspond to larger differences in observed events. Latent spaces have applications in natural language processing (e.g., word embedding), image analysis (e.g., CNN feature space), document modeling (e.g., topic modeling), and generative models (e.g., VAEs, GANs).\\n\\nThe number of dimensions in the latent space determines its specificity and generality. High-dimensional latent spaces capture detailed features, while low-dimensional spaces focus on essential aspects of the data. Finding an appropriate dimensionality balance is crucial to prevent overfitting and ensure model efficiency.'},\n",
       " {'question': 'Cross-Entropy or Log Likelihood in Output layer',\n",
       "  'tags': 'neural-networks|maximum-likelihood|softmax',\n",
       "  'answer': '**Summary (350 words):**\\n\\nNegative log likelihood and multiclass cross-entropy are equivalent concepts, representing different interpretations of the same formula. For binary classification:\\n\\n* Negative log likelihood (eq.57) applies to the Bernoulli distribution (sigmoid output), while eq.80 applies to the multinomial distribution (softmax output).\\n* The two interpretations arise from interpreting the same output probabilities differently.\\n* The softmax function outputs probabilities for all classes, while the sigmoid function outputs a single probability for one class.\\n* Despite the output difference, the underlying model and decision boundary remain the same for softmax and sigmoid.\\n* Using a split point of 0.5, the decision boundary equations for both functions are equivalent, indicating the same classification behavior.\\n* The comparison illustrates the connection between binary cross-entropy with sigmoid and multiclass cross-entropy with softmax, highlighting their underlying similarities in binary classification.'},\n",
       " {'question': 'What is batch size in neural network?',\n",
       "  'tags': 'neural-networks|python|terminology|keras',\n",
       "  'answer': '**Batch Size: Optimization in Deep Learning**\\n\\nThe batch size determines the number of samples used for network training. Using a batch size less than the total number of samples offers advantages:\\n\\n* **Reduced memory requirements:** Fewer samples reduce memory consumption, making it feasible to train with large datasets that cannot fit in memory.\\n* **Faster training:** Updating weights after each batch propagation typically speeds up training.\\n\\nHowever, smaller batch sizes compromise the accuracy of the gradient estimate, as the direction of the gradient fluctuates more. Stochastic gradient descent (SGD) uses a batch size of 1, resulting in the most gradient direction changes.\\n\\nThe optimal batch size depends on the dataset and network architecture, and a balance must be struck between memory requirements, training speed, and gradient accuracy.'}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.search(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function retrieve 5 results using TF-IDF search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ollama’s OpenAI compatible API endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1',\n",
    "    api_key='ollama',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to a create prompt using retrieved results and user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"tags: {doc['tags']}\\nquestion: {doc['question']}\\nanswer: {doc['answer']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gemma:2b\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG\n",
    "#### The function retrieves TF-IDF results based on the user's query, creates a prompt using those results, and feeds it into the LLM to generate the final response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's a breakdown of the term \"pooling layer\":\n",
      "\n",
      "**In the context of artificial intelligence (AI):**\n",
      "\n",
      "A **pooling layer** is a specific processing layer in deep neural networks that performs a downsampling operation on the input data. It is used to **reduce the dimensionality** of the data and **speed up training and inference**.\n",
      "\n",
      "**Key features of pooling layers:**\n",
      "\n",
      "* They reduce the spatial dimensions of the input by extracting a small patch of features and applying a function (such as averaging or max-pooling) to the patch.\n",
      "* They do not modify the number of channels in the input data.\n",
      "* They are common at the **input layer** of deep neural networks.\n",
      "* Pooling layers can be used with various **activation functions**, such as ReLU, max-out, and average-pooling.\n",
      "\n",
      "**Types of pooling layers:**\n",
      "\n",
      "* **Max pooling:** The maximum value from the input patch is selected.\n",
      "* **Average pooling:** The average values from the input patch are calculated.\n",
      "* **Min pooling:** The minimum value from the input patch is selected.\n",
      "* **Stochastic pooling:** A predefined percentage of the input pixels are randomly chosen.\n",
      "* **Adaptive pooling:** Different pooling kernels are applied to different parts of the input patch.\n",
      "\n",
      "**Benefits of using pooling layers:**\n",
      "\n",
      "* **Reduced computational cost:** Pooling layers significantly reduce the amount of computation needed by downsampling the input data.\n",
      "* **Improved speed:** By reducing the dimensionality of the data, pooling layers allow neural networks to train and run faster.\n",
      "* **Enhanced robustness:** Pooling layers can help to **reduce the impact of noise** in the input data.\n",
      "\n",
      "**Overall, pooling layers are an essential component of deep neural networks for:**\n",
      "\n",
      "* Reducing the model's complexity.\n",
      "* Improving training speed.\n",
      "* Enhancing data robustness.\n",
      "CPU times: user 6.2 ms, sys: 323 μs, total: 6.52 ms\n",
      "Wall time: 36.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(llm('what is pooling layer?'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
