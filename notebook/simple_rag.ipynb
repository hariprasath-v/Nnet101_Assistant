{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About\n",
    "### Build an LLM-powered RAG using a simple TF-IDF similarity search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install OpenAI -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>q_link</th>\n",
       "      <th>tags</th>\n",
       "      <th>q_question_id</th>\n",
       "      <th>q_is_answered</th>\n",
       "      <th>q_accepted_answer_id</th>\n",
       "      <th>q_view_count</th>\n",
       "      <th>q_answer_count</th>\n",
       "      <th>q_score</th>\n",
       "      <th>q_last_activity_date</th>\n",
       "      <th>q_creation_date</th>\n",
       "      <th>a_score</th>\n",
       "      <th>a_creation_date</th>\n",
       "      <th>a_answer</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to choose the number of hidden layers and ...</td>\n",
       "      <td>https://stats.stackexchange.com/questions/181/...</td>\n",
       "      <td>model-selection|neural-networks</td>\n",
       "      <td>181</td>\n",
       "      <td>True</td>\n",
       "      <td>1097</td>\n",
       "      <td>1145801</td>\n",
       "      <td>10</td>\n",
       "      <td>820</td>\n",
       "      <td>1661947755</td>\n",
       "      <td>1279584902</td>\n",
       "      <td>671</td>\n",
       "      <td>1280715630</td>\n",
       "      <td>I realize this question has been answered, but...</td>\n",
       "      <td>**Network Configuration in Neural Networks**\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What should I do when my neural network doesn&amp;...</td>\n",
       "      <td>https://stats.stackexchange.com/questions/3520...</td>\n",
       "      <td>neural-networks|faq</td>\n",
       "      <td>352036</td>\n",
       "      <td>True</td>\n",
       "      <td>352037</td>\n",
       "      <td>365434</td>\n",
       "      <td>9</td>\n",
       "      <td>368</td>\n",
       "      <td>1701358003</td>\n",
       "      <td>1529367960</td>\n",
       "      <td>455</td>\n",
       "      <td>1529367960</td>\n",
       "      <td>1.  Verify that your code is bug free\\nThere's...</td>\n",
       "      <td>**Key Considerations for Neural Network Develo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What exactly are keys, queries, and values in ...</td>\n",
       "      <td>https://stats.stackexchange.com/questions/4219...</td>\n",
       "      <td>neural-networks|natural-language|attention|mac...</td>\n",
       "      <td>421935</td>\n",
       "      <td>True</td>\n",
       "      <td>424127</td>\n",
       "      <td>261109</td>\n",
       "      <td>11</td>\n",
       "      <td>309</td>\n",
       "      <td>1708928023</td>\n",
       "      <td>1565686855</td>\n",
       "      <td>281</td>\n",
       "      <td>1567068576</td>\n",
       "      <td>The key/value/query formulation of attention i...</td>\n",
       "      <td>In the key/value/query formulation of attentio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is batch size in neural network?</td>\n",
       "      <td>https://stats.stackexchange.com/questions/1535...</td>\n",
       "      <td>neural-networks|python|terminology|keras</td>\n",
       "      <td>153531</td>\n",
       "      <td>True</td>\n",
       "      <td>153535</td>\n",
       "      <td>731148</td>\n",
       "      <td>6</td>\n",
       "      <td>305</td>\n",
       "      <td>1650529048</td>\n",
       "      <td>1432286121</td>\n",
       "      <td>421</td>\n",
       "      <td>1432288067</td>\n",
       "      <td>The batch size defines the number of samples t...</td>\n",
       "      <td>**Summary**\\n\\n**Batch Size**\\n\\nBatch size de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the advantages of ReLU over sigmoid f...</td>\n",
       "      <td>https://stats.stackexchange.com/questions/1262...</td>\n",
       "      <td>machine-learning|neural-networks|sigmoid-curve...</td>\n",
       "      <td>126238</td>\n",
       "      <td>True</td>\n",
       "      <td>126362</td>\n",
       "      <td>290897</td>\n",
       "      <td>9</td>\n",
       "      <td>234</td>\n",
       "      <td>1723495231</td>\n",
       "      <td>1417486429</td>\n",
       "      <td>205</td>\n",
       "      <td>1417567286</td>\n",
       "      <td>Two additional major benefits of ReLUs are spa...</td>\n",
       "      <td>**Summary:**\\n\\nRectified Linear Units (ReLUs)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  How to choose the number of hidden layers and ...   \n",
       "1  What should I do when my neural network doesn&...   \n",
       "2  What exactly are keys, queries, and values in ...   \n",
       "3              What is batch size in neural network?   \n",
       "4  What are the advantages of ReLU over sigmoid f...   \n",
       "\n",
       "                                              q_link  \\\n",
       "0  https://stats.stackexchange.com/questions/181/...   \n",
       "1  https://stats.stackexchange.com/questions/3520...   \n",
       "2  https://stats.stackexchange.com/questions/4219...   \n",
       "3  https://stats.stackexchange.com/questions/1535...   \n",
       "4  https://stats.stackexchange.com/questions/1262...   \n",
       "\n",
       "                                                tags  q_question_id  \\\n",
       "0                    model-selection|neural-networks            181   \n",
       "1                                neural-networks|faq         352036   \n",
       "2  neural-networks|natural-language|attention|mac...         421935   \n",
       "3           neural-networks|python|terminology|keras         153531   \n",
       "4  machine-learning|neural-networks|sigmoid-curve...         126238   \n",
       "\n",
       "   q_is_answered  q_accepted_answer_id  q_view_count  q_answer_count  q_score  \\\n",
       "0           True                  1097       1145801              10      820   \n",
       "1           True                352037        365434               9      368   \n",
       "2           True                424127        261109              11      309   \n",
       "3           True                153535        731148               6      305   \n",
       "4           True                126362        290897               9      234   \n",
       "\n",
       "   q_last_activity_date  q_creation_date  a_score  a_creation_date  \\\n",
       "0            1661947755       1279584902      671       1280715630   \n",
       "1            1701358003       1529367960      455       1529367960   \n",
       "2            1708928023       1565686855      281       1567068576   \n",
       "3            1650529048       1432286121      421       1432288067   \n",
       "4            1723495231       1417486429      205       1417567286   \n",
       "\n",
       "                                            a_answer  \\\n",
       "0  I realize this question has been answered, but...   \n",
       "1  1.  Verify that your code is bug free\\nThere's...   \n",
       "2  The key/value/query formulation of attention i...   \n",
       "3  The batch size defines the number of samples t...   \n",
       "4  Two additional major benefits of ReLUs are spa...   \n",
       "\n",
       "                                              answer  \n",
       "0  **Network Configuration in Neural Networks**\\n...  \n",
       "1  **Key Considerations for Neural Network Develo...  \n",
       "2  In the key/value/query formulation of attentio...  \n",
       "3  **Summary**\\n\\n**Batch Size**\\n\\nBatch size de...  \n",
       "4  **Summary:**\\n\\nRectified Linear Units (ReLUs)...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'https://raw.githubusercontent.com/hariprasath-v/Nnet101_Assistant/refs/heads/main/data/Stackoverflow_data(neural_networks_stats)_pre_processed_Gemini_LLM.csv'\n",
    "data = pd.read_csv(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get TF-IDF minisearch code from [DataTalks LLM Zoomcamp](https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/minsearch.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-05 06:37:13--  https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3832 (3.7K) [text/plain]\n",
      "Saving to: ‘minsearch.py.1’\n",
      "\n",
      "minsearch.py.1      100%[===================>]   3.74K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-10-05 06:37:13 (31.9 MB/s) - ‘minsearch.py.1’ saved [3832/3832]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!wget https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import minisearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = data[['question','tags','answer']].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How to choose the number of hidden layers and nodes in a feedforward neural network?',\n",
       " 'tags': 'model-selection|neural-networks',\n",
       " 'answer': \"**Network Configuration in Neural Networks**\\n\\n**Standardization**\\nThere is no single standardized method for configuring networks. However, guidelines exist for setting the number and type of network layers, as well as the number of neurons in each layer.\\n\\n**Initial Architecture Setup**\\nBy following specific rules, one can establish a competent network architecture. This involves determining the number and type of neuronal layers and the number of neurons within each layer. This approach provides a foundational architecture but may not be optimal.\\n\\n**Iterative Tuning**\\nOnce the network is initialized, its configuration can be iteratively tuned during training. Ancillary algorithms, such as pruning, can be used to eliminate unnecessary nodes, optimizing the network's size and performance.\\n\\n**Network Layer Types and Sizing**\\nEvery neural network has input, hidden, and output layers.\\n\\n* **Input Layer:** Number of neurons is determined by the number of features in the training data.\\n* **Output Layer:** Number of neurons is determined by the model configuration (regression mode has one node, classification mode uses softmax for multiple classes).\\n* **Hidden Layers:** Number of layers and neurons can be determined empirically, with one hidden layer often being sufficient. Rule of thumb suggests the hidden layer size should be between the input and output layer sizes.\\n\\n**Optimization**\\nPruning techniques can be employed during training to reduce network size and improve performance. This involves identifying and removing nodes that do not significantly impact network performance. Optimizing network configuration can be achieved by initially setting a larger number of neurons and then using pruning to refine the network.\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample TF-IDF search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\",  \"answer\"],\n",
    "    keyword_fields=[\"tag\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x7802d6e1f110>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.fit(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'what is pooling layer?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'What is global max pooling layer and what is its advantage over maxpooling layer?',\n",
       "  'tags': 'neural-networks|convolutional-neural-network|pooling',\n",
       "  'answer': '**Summary:**\\n\\nGlobal max pooling is a type of max pooling where the pool size is equal to the input size. Unlike regular max pooling, which produces a smaller output, global max pooling produces an output with the same dimensionality as the input.\\n\\nIn global max pooling, the maximum value across the entire input is extracted, providing a representation that focuses on the most prominent feature. This is useful in applications like natural language processing, where the most important words in a sentence are often indicative of its meaning.\\n\\nIn contrast, regular max pooling divides the input into smaller segments and extracts the maximum value from each segment, reducing the output size. This is more common in computer vision, where spatial information is important and reducing the size of the representation can be beneficial for computational efficiency.'},\n",
       " {'question': 'Feature extracted by max pooling vs mean pooling',\n",
       "  'tags': 'machine-learning|deep-learning|feature-engineering|computer-vision',\n",
       "  'answer': 'Convolutional layers extract features from input data, while pooling layers compress these features to reduce dimensionality. There are two main types of pooling layers: max-pooling and mean-pooling.\\n\\n**Max-pooling** selects the maximum activation value within a block of data, prioritizing the presence of a specific feature in a general area. However, it can lose information about low activations within that block.\\n\\n**Mean-pooling** calculates the average activation value within a block, which can smooth out large activations. It retains some information about low activations but may not capture the presence of specific features as strongly as max-pooling.\\n\\nThe choice between max-pooling and mean-pooling depends on the desired level of feature extraction and the importance of preserving low activation information.'},\n",
       " {'question': 'Why is max pooling necessary in convolutional neural networks?',\n",
       "  'tags': 'deep-learning|convolutional-neural-network|pooling',\n",
       "  'answer': '**Summary:**\\n\\nPooling layers in convolutional neural networks (CNNs) offer some translation invariance and computational efficiency. However, they can be replaced by convolutions with stride, which may yield superior results.\\n\\nSome recent CNN architectures, such as Wide Residual Networks and DenseNets, employ average pooling. Others, like DelugeNets, utilize convolutions with stride. The optimal choice between pooling and convolutions can vary depending on the network architecture and task.\\n\\nOverall, the use of convolutions with stride can be a viable alternative to pooling layers in CNNs, offering the potential for enhanced performance.'},\n",
       " {'question': 'Difference between pooling and subsampling',\n",
       "  'tags': 'neural-networks|convolutional-neural-network|computer-vision',\n",
       "  'answer': '**Summary:**\\n\\nPooling layers in convolutional neural networks (CNNs) perform a form of subsampling that reduces the dimensionality of the input data. This process of reducing the size of the data while retaining its essential features is known as subsampling.\\n\\nThe paper \"Gradient-Based Learning Applied to Document Recognition\" by Yann LeCun refers to subsampling as a pooling layer. This suggests that pooling layers can be used to perform subsampling operations in CNNs.\\n\\nIn essence, pooling operations are a type of subsampling that reduce the size of the image while preserving its important characteristics. This makes them a crucial component in CNNs for efficiently extracting features from images.'},\n",
       " {'question': 'What is an embedding layer in a neural network?',\n",
       "  'tags': 'machine-learning|neural-networks|python|word-embeddings',\n",
       "  'answer': '**Relation to Word2Vec:**\\nWord2Vec embodies words as vectors in a continuous space, allowing for similarity comparisons based on vector distance. This enables the distributed representation of n-grams and the analysis of semantic relationships.\\n\\n**Lasagne Code Explanation:**\\nThe code snippet demonstrates the use of Lasagne to create a word embedding layer. The vocabulary size is defined as 3, and each word is embedded as a 5-dimensional vector. The word embedding matrix is initialized with values from 0 to 14.\\n\\nThe data is then represented as 2-grams in a sparse matrix format, where each row represents a 2-gram. The embedding function is applied to these 2-grams, resulting in a matrix that represents each 2-gram as a pair of 5-dimensional vectors. The dimensions of the output matrix are consistent with the vocabulary size and embedding size specified in the code.'},\n",
       " {'question': 'What does a bottleneck layer mean in neural networks?',\n",
       "  'tags': 'neural-networks|image-processing',\n",
       "  'answer': \"**Summary:**\\n\\nA bottleneck layer in a neural network is a layer with fewer nodes than the preceding layers. It compresses the dimensionality of the input representation. Autoencoders with bottleneck layers are used for nonlinear dimensionality reduction.\\n\\nIn a typical application, a pre-trained deep network for face classification is utilized. Its early layers, up to an intermediate bottleneck layer, form a subnetwork that maps input faces to lower-dimensional feature vectors. This bottleneck layer representation allows for efficient representation and classification of new faces.\\n\\nClassifier layers can be added to the bottleneck layer to extend the network's classification capabilities to new identities. Alternatively, the bottleneck layer representation can be used as input to other classification models for improved performance.\"},\n",
       " {'question': 'What is the architecture of a stacked convolutional autoencoder?',\n",
       "  'tags': 'neural-networks|deep-learning|autoencoders|deep-belief-networks',\n",
       "  'answer': '**Summary:**\\n\\nStacked-convolutional autoencoders involve using a sequence of convolutional layers to encode and decode data. To recover output from the encoder, pooling operations must be reversed through reverse-pooling and convolution.\\n\\nTraditionally, each layer in the autoencoder is trained separately, followed by stacking and retraining the entire network. However, research by Yoshua Bengio suggests training a fully-stacked network from scratch.\\n\\nA \"noise layer\" can inject variability into the input to prevent overfitting. To fine-tune weights through error back-propagation, the reconstruction phase (reverse-pooling, deconvolution) is necessary.\\n\\nDespite extensive research, comprehensive architectural explanations of stacked-convolutional autoencoders remain scarce.'},\n",
       " {'question': 'What does the hidden layer in a neural network compute?',\n",
       "  'tags': 'machine-learning|neural-networks|nonlinear-regression',\n",
       "  'answer': \"**Three-sentence summary:**\\n\\nNeural networks apply functions such as linear transformations and nonlinearities to data, with each layer building upon the previous one. Hidden layers transform the data for easier processing by the output layer, which produces the final result.\\n\\n**Like you're 5:**\\n\\nImagine you want a computer to recognize buses. You can create detectors for wheels, boxes, and size. These detectors work together in hidden layers to form a toolset for bus recognition. If all detectors are active, there's a good chance a bus is present. Neural networks provide easy ways to combine many detectors.\\n\\n**Like you're an adult:**\\n\\nNeural networks apply functions (e.g., linear transformations and nonlinearities) to data, with subsequent layers building upon each other. The hidden layer's activation (transformation of input) is fed as input to the output layer, which produces the network's output. The combination of multiple functions allows the network to perform complex tasks.\"},\n",
       " {'question': 'Softmax layer in a neural network',\n",
       "  'tags': 'neural-networks',\n",
       "  'answer': \"**Summary:**\\n\\nComputing the gradient for a neural network involves deriving the Jacobian matrix, which captures the relationship between changes in the input and output layer errors. The Jacobian's diagonal elements represent the gradient of the diagonal of the matrix, while the off-diagonal elements represent the gradient of the off-diagonal entries. These elements can be combined using the Kronecker Delta function, resulting in the following definition for the gradient:\\n\\n```\\n∂h_i / ∂z_j = h_i(δ_{ij} - h_j)\\n```\\n\\nTo obtain the input errors from the output errors, the gradient of the output error (∇h_i) is computed for each input dimension. These gradients are then summed and multiplied by the Jacobian matrix (J) to obtain the gradient of the input (∇x).\\n\\nIn the case of a softmax output layer and cross-entropy cost model, the calculation simplifies to:\\n\\n```\\nσ_l = h - t\\n```\\n\\nwhere σ_l is the gradient of the logarithmic likelihood error, h is the output of the softmax function, and t is the vector of labels. This simplified form is convenient and numerically stable for neural network training.\"},\n",
       " {'question': 'How does the DepthConcat operation in &#39;Going deeper with convolutions&#39; work?',\n",
       "  'tags': 'neural-networks|torch|convolutional-neural-network',\n",
       "  'answer': 'An inception module in a neural network consists of multiple convolutional layers and a pooling layer. The convolutional layers are typically padded to maintain the spatial resolution (size) of the input. The pooling layer used in inception modules has a stride of 1, which means it operates like a convolutional layer but with the convolution operation replaced by a max operation. This ensures that the spatial resolution after the pooling layer remains the same as the input. As a result, the output of an inception module maintains the spatial resolution of the input, allowing for concatenation of the convolutional and pooling layer outputs along the \"depth\" dimension.'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.search(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function retrieve 5 results using TF-IDF search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ollama’s OpenAI compatible API endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1',\n",
    "    api_key='ollama',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to a create prompt using retrieved results and user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"tags: {doc['tags']}\\nquestion: {doc['question']}\\nanswer: {doc['answer']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gemma:2b\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG\n",
    "#### The function retrieves TF-IDF results based on the user's query, creates a prompt using those results, and feeds it into the LLM to generate the final response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure. Here's a definition of a pooling layer:\n",
      "\n",
      "**Pooling Layer**\n",
      "\n",
      "A pooling layer is a type of layer used in deep learning neural networks for reducing the dimensionality of feature maps and increasing computational efficiency. It involves taking a subset of the input features and using them to represent the entire input.\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "* **Supervised learning:** Polling layers are typically used in convolutional neural networks (CNNs) for tasks like image classification, object detection, and segmentation.\n",
      "* **Spatial pooling:** They operate by taking a fixed size pool of features from the input and then applying a non-linear transformation on the pooled representation.\n",
      "* **Feature extraction:** The output of a pooling layer is a smaller, more compact representation of the input that captures the essential features of the original data.\n",
      "* **Dimensionality reduction:** By reducing the dimensionality of feature maps, pooling layers can help to:\n",
      "    * Reduce the memory consumption of neural networks.\n",
      "    * Enhance the performance of subsequent layers by reducing noise and redundancy.\n",
      "    * Make the model more robust to data variations.\n",
      "\n",
      "**Types of Pooling Layers:**\n",
      "\n",
      "* **Max pooling:** Takes the maximum value from the selected features and represents the input as a single vector.\n",
      "* **Average pooling:** Calculates the average of the selected features and represents the input as a single vector.\n",
      "* **Median pooling:** Takes the median value from the selected features and represents the input as a single vector.\n",
      "\n",
      "**Applications:**\n",
      "\n",
      "* **Feature extraction:** Polling layers can be used to extract meaningful features from input data, which can then be used by subsequent layers in the network.\n",
      "* **Dimensionality reduction:** As mentioned earlier, pooling layers can reduce the dimensionality of feature maps, which can improve the performance of subsequent layers.\n",
      "* **Spatial understanding:** By pooling features along the spatial dimensions (e.g., rows and columns), they can capture local relationships between different parts of the input.\n",
      "\n",
      "**Benefits:**\n",
      "\n",
      "* **Improved computational efficiency:** By reducing the dimensionality of feature maps, pooling layers can make training and inference faster.\n",
      "* **Enhanced robustness:** They can help to make the model more robust to data variations.\n",
      "* **Feature extraction:** Pooling layers can be used to extract insightful features from the input data, which can improve the performance of subsequent layers.\n",
      "CPU times: user 10.4 ms, sys: 1.31 ms, total: 11.7 ms\n",
      "Wall time: 46.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(llm('what is pooling layer?'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
