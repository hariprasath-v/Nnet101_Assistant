{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About\n",
    "### Build an LLM-powered RAG using Elasticsearch with vectors ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install OpenAI -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install elasticsearch -qq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade ipywidgets -qq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence_transformers -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import json\n",
    "import elasticsearch\n",
    "from elasticsearch import Elasticsearch\n",
    "from tqdm.notebook import tqdm, tqdm_notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_title</th>\n",
       "      <th>q_link</th>\n",
       "      <th>q_tags</th>\n",
       "      <th>q_question_id</th>\n",
       "      <th>q_is_answered</th>\n",
       "      <th>q_accepted_answer_id</th>\n",
       "      <th>q_view_count</th>\n",
       "      <th>q_answer_count</th>\n",
       "      <th>q_score</th>\n",
       "      <th>q_last_activity_date</th>\n",
       "      <th>q_creation_date</th>\n",
       "      <th>a_score</th>\n",
       "      <th>a_creation_date</th>\n",
       "      <th>a_answer</th>\n",
       "      <th>llm_answer_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to choose the number of hidden layers and ...</td>\n",
       "      <td>https://stats.stackexchange.com/questions/181/...</td>\n",
       "      <td>['model-selection', 'neural-networks']</td>\n",
       "      <td>181</td>\n",
       "      <td>True</td>\n",
       "      <td>1097</td>\n",
       "      <td>1145532</td>\n",
       "      <td>10</td>\n",
       "      <td>820</td>\n",
       "      <td>1661947755</td>\n",
       "      <td>1279584902</td>\n",
       "      <td>671</td>\n",
       "      <td>1280715630</td>\n",
       "      <td>I realize this question has been answered, but...</td>\n",
       "      <td>**Network Configuration in Neural Networks**\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What should I do when my neural network doesn&amp;...</td>\n",
       "      <td>https://stats.stackexchange.com/questions/3520...</td>\n",
       "      <td>['neural-networks', 'faq']</td>\n",
       "      <td>352036</td>\n",
       "      <td>True</td>\n",
       "      <td>352037</td>\n",
       "      <td>365347</td>\n",
       "      <td>9</td>\n",
       "      <td>368</td>\n",
       "      <td>1701358003</td>\n",
       "      <td>1529367960</td>\n",
       "      <td>455</td>\n",
       "      <td>1529367960</td>\n",
       "      <td>1.  Verify that your code is bug free\\nThere's...</td>\n",
       "      <td>**Summary:**\\n\\nBuilding neural networks requi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What exactly are keys, queries, and values in ...</td>\n",
       "      <td>https://stats.stackexchange.com/questions/4219...</td>\n",
       "      <td>['neural-networks', 'natural-language', 'atten...</td>\n",
       "      <td>421935</td>\n",
       "      <td>True</td>\n",
       "      <td>424127</td>\n",
       "      <td>260772</td>\n",
       "      <td>11</td>\n",
       "      <td>309</td>\n",
       "      <td>1708928023</td>\n",
       "      <td>1565686855</td>\n",
       "      <td>281</td>\n",
       "      <td>1567068576</td>\n",
       "      <td>The key/value/query formulation of attention i...</td>\n",
       "      <td>Attention is a retrieval process that involves...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is batch size in neural network?</td>\n",
       "      <td>https://stats.stackexchange.com/questions/1535...</td>\n",
       "      <td>['neural-networks', 'python', 'terminology', '...</td>\n",
       "      <td>153531</td>\n",
       "      <td>True</td>\n",
       "      <td>153535</td>\n",
       "      <td>730947</td>\n",
       "      <td>6</td>\n",
       "      <td>305</td>\n",
       "      <td>1650529048</td>\n",
       "      <td>1432286121</td>\n",
       "      <td>421</td>\n",
       "      <td>1432288067</td>\n",
       "      <td>The batch size defines the number of samples t...</td>\n",
       "      <td>**Batch Size: Optimization in Deep Learning**\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the advantages of ReLU over sigmoid f...</td>\n",
       "      <td>https://stats.stackexchange.com/questions/1262...</td>\n",
       "      <td>['machine-learning', 'neural-networks', 'sigmo...</td>\n",
       "      <td>126238</td>\n",
       "      <td>True</td>\n",
       "      <td>126362</td>\n",
       "      <td>290838</td>\n",
       "      <td>9</td>\n",
       "      <td>234</td>\n",
       "      <td>1723495231</td>\n",
       "      <td>1417486429</td>\n",
       "      <td>205</td>\n",
       "      <td>1417567286</td>\n",
       "      <td>Two additional major benefits of ReLUs are spa...</td>\n",
       "      <td>ReLU (Rectified Linear Unit) functions, define...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             q_title  \\\n",
       "0  How to choose the number of hidden layers and ...   \n",
       "1  What should I do when my neural network doesn&...   \n",
       "2  What exactly are keys, queries, and values in ...   \n",
       "3              What is batch size in neural network?   \n",
       "4  What are the advantages of ReLU over sigmoid f...   \n",
       "\n",
       "                                              q_link  \\\n",
       "0  https://stats.stackexchange.com/questions/181/...   \n",
       "1  https://stats.stackexchange.com/questions/3520...   \n",
       "2  https://stats.stackexchange.com/questions/4219...   \n",
       "3  https://stats.stackexchange.com/questions/1535...   \n",
       "4  https://stats.stackexchange.com/questions/1262...   \n",
       "\n",
       "                                              q_tags  q_question_id  \\\n",
       "0             ['model-selection', 'neural-networks']            181   \n",
       "1                         ['neural-networks', 'faq']         352036   \n",
       "2  ['neural-networks', 'natural-language', 'atten...         421935   \n",
       "3  ['neural-networks', 'python', 'terminology', '...         153531   \n",
       "4  ['machine-learning', 'neural-networks', 'sigmo...         126238   \n",
       "\n",
       "   q_is_answered  q_accepted_answer_id  q_view_count  q_answer_count  q_score  \\\n",
       "0           True                  1097       1145532              10      820   \n",
       "1           True                352037        365347               9      368   \n",
       "2           True                424127        260772              11      309   \n",
       "3           True                153535        730947               6      305   \n",
       "4           True                126362        290838               9      234   \n",
       "\n",
       "   q_last_activity_date  q_creation_date  a_score  a_creation_date  \\\n",
       "0            1661947755       1279584902      671       1280715630   \n",
       "1            1701358003       1529367960      455       1529367960   \n",
       "2            1708928023       1565686855      281       1567068576   \n",
       "3            1650529048       1432286121      421       1432288067   \n",
       "4            1723495231       1417486429      205       1417567286   \n",
       "\n",
       "                                            a_answer  \\\n",
       "0  I realize this question has been answered, but...   \n",
       "1  1.  Verify that your code is bug free\\nThere's...   \n",
       "2  The key/value/query formulation of attention i...   \n",
       "3  The batch size defines the number of samples t...   \n",
       "4  Two additional major benefits of ReLUs are spa...   \n",
       "\n",
       "                                  llm_answer_summary  \n",
       "0  **Network Configuration in Neural Networks**\\n...  \n",
       "1  **Summary:**\\n\\nBuilding neural networks requi...  \n",
       "2  Attention is a retrieval process that involves...  \n",
       "3  **Batch Size: Optimization in Deep Learning**\\...  \n",
       "4  ReLU (Rectified Linear Unit) functions, define...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'https://raw.githubusercontent.com/hariprasath-v/Nnet101_Assistant/refs/heads/main/data/Stackoverflow_data(neural_networks_stats)_pre_processed_Gemini_LLM.csv'\n",
    "data = pd.read_csv(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing\n",
    "#### combine tags with pipe operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model-selection', 'neural-networks']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast.literal_eval(data['q_tags'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['q_tags'] = data['q_tags'].apply(lambda x: \"|\".join(i.strip() for i in ast.literal_eval(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = data[['q_title','q_tags','llm_answer_summary']].rename(columns={'q_title':'question','q_tags':'tags','llm_answer_summary':'answer'}).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elasticsearch setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200/', request_timeout=60) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\" : \"b1e0dee937f4\",\n",
      "  \"cluster_name\" : \"docker-cluster\",\n",
      "  \"cluster_uuid\" : \"VR6OBcGxS8yGbVNXfQ3enQ\",\n",
      "  \"version\" : {\n",
      "    \"number\" : \"8.4.3\",\n",
      "    \"build_flavor\" : \"default\",\n",
      "    \"build_type\" : \"docker\",\n",
      "    \"build_hash\" : \"42f05b9372a9a4a470db3b52817899b99a76ee73\",\n",
      "    \"build_date\" : \"2022-10-04T07:17:24.662462378Z\",\n",
      "    \"build_snapshot\" : false,\n",
      "    \"lucene_version\" : \"9.3.0\",\n",
      "    \"minimum_wire_compatibility_version\" : \"7.17.0\",\n",
      "    \"minimum_index_compatibility_version\" : \"7.0.0\"\n",
      "  },\n",
      "  \"tagline\" : \"You Know, for Search\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl localhost:9200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating embedding using sentence transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's embed a sentence and see the dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.encode(\"This is a simple sentence\",show_progress_bar=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How to choose the number of hidden layers and nodes in a feedforward neural network?',\n",
       " 'tags': 'model-selection|neural-networks',\n",
       " 'answer': '**Network Configuration in Neural Networks**\\n\\nNeural networks require network configuration, which involves determining the number and types of layers and the number of neurons within each layer.\\n\\n**Standard Method:**\\n\\n* Initialize a competent network architecture using a set of rules that determine the number and size of input, hidden, and output layers.\\n\\n**Optimization:**\\n\\n* Once initialized, the network configuration can be iteratively tuned during training using pruning techniques.\\n* Pruning eliminates unnecessary nodes based on their low weight values.\\n\\n**Layer Configuration:**\\n\\n* Input layer: Number of neurons determined by the number of features in the training data.\\n* Output layer: Number of neurons determined by the model configuration (classifier vs. regressor).\\n* Hidden layers: Typically one hidden layer is sufficient, and its size can be estimated as the mean of the input and output layer sizes.\\n\\n**Optimization Process:**\\n\\n* Initialize with a larger network configuration to allow for pruning.\\n* Apply a pruning algorithm during training to identify and remove redundant nodes.\\n* This two-step optimization approach is commonly used to approach optimal network configuration.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create embedding for answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5558d54edc00428dafc0a085bb5000b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#created the dense vector using the pre-trained model\n",
    "operations = []\n",
    "for doc in tqdm(data_1):\n",
    "    # Transforming the title into an embedding using the model\n",
    "    doc[\"answer_vector\"] = model.encode(doc[\"answer\"],show_progress_bar=False,normalize_embeddings=True).tolist()\n",
    "    operations.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: 58\n",
      "tags: 19\n",
      "answer: 1790\n",
      "answer_vector: 384\n"
     ]
    }
   ],
   "source": [
    "for k,v in operations[1].items():\n",
    "    print(f\"{k}: {len(v)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and add index to elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'nnet101'})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dimension=384\n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"answer\": {\"type\": \"text\"},\n",
    "            \"tags\": {\"type\": \"keyword\"},\n",
    "            \"answer_vector\": {\"type\": \"dense_vector\", \"dims\": model_dimension, \"index\": True, \"similarity\": \"cosine\"},\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"nnet101\"\n",
    "\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edbae2c9029d41a196dd9da149dd9291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm_notebook(data_1):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create query and embed it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = \"What is pooling layer?\"\n",
    "vector_search_term = model.encode(search_term,show_progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_search_term.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"field\": \"answer_vector\",\n",
    "    \"query_vector\": vector_search_term,\n",
    "    \"k\": 5,\n",
    "    \"num_candidates\": 10000, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_index': 'nnet101',\n",
       "  '_id': 'vA5fYZIBY9iTjmQApslC',\n",
       "  '_score': 0.79374504,\n",
       "  '_source': {'question': 'What is global max pooling layer and what is its advantage over maxpooling layer?',\n",
       "   'answer': \"Global max pooling is a max pooling operation where the pool size equals the input size. It outputs the maximum value for each feature across the input's temporal dimension. Ordinary max pooling, in contrast, takes a specified pool size and outputs maximum values within that window.\\n\\nIn Keras, the `GlobalMaxPooling1D` layer performs global max pooling on 1D temporal data. It converts a 3D tensor (samples, steps, features) to a 2D tensor (samples, features).\\n\\nGlobal max pooling is commonly used in domains like natural language processing, while ordinary max pooling is more prevalent in domains like computer vision.\",\n",
       "   'tags': 'neural-networks|conv-neural-network|pooling'}},\n",
       " {'_index': 'nnet101',\n",
       "  '_id': 'AA5fYZIBY9iTjmQAqMqQ',\n",
       "  '_score': 0.73397934,\n",
       "  '_source': {'question': 'What does kernel size mean?',\n",
       "   'answer': \"Deep neural networks, particularly convolutional neural networks (CNNs), consist of layers defined by the application of filters (kernels) on the input. Kernels in convolutional layers perform cross-correlation, not convolution, and determine the filter's size. Max pooling layers select the pixel with the highest value from a set defined by the kernel, subsampling the input. Unlike kernels in support vector machines or regularization networks, CNN kernels are feature extractors, identifying patterns and features in the data.\",\n",
       "   'tags': 'machine-learning|neural-networks'}},\n",
       " {'_index': 'nnet101',\n",
       "  '_id': '9Q5fYZIBY9iTjmQAqMkt',\n",
       "  '_score': 0.718433,\n",
       "  '_source': {'question': 'Why is max pooling necessary in convolutional neural networks?',\n",
       "   'answer': \"**Summary:**\\n\\nPooling layers, while providing translation invariance and computational speed, may not always be optimal.\\n\\nRecent research suggests that replacing pooling with convolutional layers with stride can improve performance. Experiments have shown success with average pooling (in Wide Residual Networks and DenseNets) and convolutional stride (in DelugeNets).\\n\\nThis strategy eliminates pooling's drawbacks while maintaining its benefits, allowing for more efficient and accurate convolution-based neural networks.\",\n",
       "   'tags': 'deep-learning|conv-neural-network|pooling'}},\n",
       " {'_index': 'nnet101',\n",
       "  '_id': 'rA5fYZIBY9iTjmQApcmm',\n",
       "  '_score': 0.6740511,\n",
       "  '_source': {'question': 'What does the hidden layer in a neural network compute?',\n",
       "   'answer': \"Feed-forward neural networks apply functions to transform data sequentially. Each layer performs a linear transformation followed by a non-linearity. The hidden layers modify inputs to assist the output layer in generating the desired output. The functions used vary depending on the network, but commonly include logical operators or image processing functions.\\n\\nEach layer's role is determined by the functions it computes. The output of a layer is the result of applying multiple functions to the input. This allows networks to represent complex relationships that cannot be expressed by a single function.\\n\\nIn practical applications, hidden layers are designed to detect specific features in data (e.g., edges in images). These features are then combined by subsequent layers to form more complex representations (e.g., eyes in an image). This hierarchical approach makes it easier to identify high-level patterns and perform complex tasks.\",\n",
       "   'tags': 'machine-learning|neural-networks|nonlinear-regression'}},\n",
       " {'_index': 'nnet101',\n",
       "  '_id': '_g5fYZIBY9iTjmQAqMmH',\n",
       "  '_score': 0.6686587,\n",
       "  '_source': {'question': 'How do bottleneck architectures work in neural networks?',\n",
       "   'answer': \"The bottleneck architecture, employed in deep neural networks, aims to reduce computational load. This approach involves a sequential arrangement of layers with varying dimensions.\\n\\nIn a bottleneck block, the input feature maps are reduced in size to minimize dimensionality and computational cost. The block is characterized by a specific number of feature maps (e.g., 64-d), which represents the number of filters employed in the convolution operations.\\n\\nVariations in the bottleneck architecture exist, such as the ResNet architecture, which utilizes 256-d feature maps. This difference stems from the network's depth and the resolution of the input images. Deeper networks with higher resolution inputs require more feature maps to process the increased data volume.\\n\\nTo further illustrate these concepts, a reference figure can be consulted, providing detailed parameters for each bottleneck layer in the ResNet 50 architecture. By studying this figure, one can gain insights into the specific dimensions and configurations used in this popular deep neural network model.\",\n",
       "   'tags': 'residuals|deep-learning|conv-neural-network'}}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = es_client.search(index=index_name, knn=query, source=[\"answer\", \"tags\", \"question\"])\n",
    "res[\"hits\"][\"hits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model-selection|neural-networks'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1[0]['tags']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elasticsearch knn similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_search(search_query):\n",
    "    vector_search_term = model.encode(search_query,show_progress_bar=False)\n",
    "    \n",
    "    knn_query = {\n",
    "        \"field\": \"answer_vector\",\n",
    "        \"query_vector\": vector_search_term,\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000\n",
    "    }\n",
    "    \n",
    " \n",
    "    \n",
    "\n",
    "    response = es_client.search(\n",
    "        index=index_name,\n",
    "\n",
    "        knn=knn_query,\n",
    "        size=5\n",
    "    )\n",
    "    result1 = {k: v for k,v in response[\"hits\"][\"hits\"][0].items() if k != \"_source\"}\n",
    "    result2 = ({k: v for k, v in response[\"hits\"][\"hits\"][0]['_source'].items() if k != 'answer_vector'})\n",
    "    final_result = {**result1, **result2}\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_index': 'nnet101',\n",
       " '_id': 'vA5fYZIBY9iTjmQApslC',\n",
       " '_score': 0.79374504,\n",
       " 'question': 'What is global max pooling layer and what is its advantage over maxpooling layer?',\n",
       " 'tags': 'neural-networks|conv-neural-network|pooling',\n",
       " 'answer': \"Global max pooling is a max pooling operation where the pool size equals the input size. It outputs the maximum value for each feature across the input's temporal dimension. Ordinary max pooling, in contrast, takes a specified pool size and outputs maximum values within that window.\\n\\nIn Keras, the `GlobalMaxPooling1D` layer performs global max pooling on 1D temporal data. It converts a 3D tensor (samples, steps, features) to a 2D tensor (samples, features).\\n\\nGlobal max pooling is commonly used in domains like natural language processing, while ordinary max pooling is more prevalent in domains like computer vision.\"}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_search(search_query='what is pooling layer?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ollama’s OpenAI compatible API endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1',\n",
    "    api_key='ollama',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to a create prompt using retrieved results and user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"tags: {doc['tags']}\\nquestion: {doc['question']}\\nanswer: {doc['answer']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gemma:2b\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG\n",
    "#### The function retrieves elasticsearch knn similarity results based on the user's query, creates a prompt using those results, and feeds it into the LLM to generate the final response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = knn_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure. Here is the definition of a pooling layer:\n",
      "\n",
      "**Pooling layer** is a type of neural network layer that reduces the dimensionality of a feature map by taking a subset of the input features and using them to represent the whole feature map. The output of the pooling layer is a single value or vector, which represents the feature map as a whole.\n",
      "\n",
      "**Here are some of the key characteristics of pooling layers:**\n",
      "\n",
      "* They operate on feature maps, which are 2D tensors of feature maps.\n",
      "* They take a subset of the input features and use them to represent the whole feature map.\n",
      "* The size of the subset can be specified by the pool size parameter.\n",
      "* Pooling layers can be used as part of a convolutional neural network (CNN).\n",
      "\n",
      "**Types of Pooling Layers:**\n",
      "\n",
      "* **Average pooling layer:** The average value of the input features is taken to represent the output value.\n",
      "* **Max pooling layer:** The maximum value of the input features is taken to represent the output value.\n",
      "* **Max-pooling layer:** This is a variant of the max pooling layer that takes the maximum value of the input features in a window of the specified size.\n",
      "* **Adaptive pooling layer:** This layer can be used to adapt the size of the feature map to the size of the input data.\n",
      "\n",
      "**Advantages of Pooling Layers:**\n",
      "\n",
      "* They reduce the dimensionality of the feature map, which can make it easier for the subsequent layers in a neural network to learn.\n",
      "* They can help to reduce the computational cost of training a neural network.\n",
      "\n",
      "**Disadvantages of Pooling Layers:**\n",
      "\n",
      "* They can sometimes reduce the quality of the feature map, as they can lose information from the smaller subset of features.\n",
      "* They can be sensitive to the size of the pool size parameter.\n",
      "CPU times: user 10.2 ms, sys: 0 ns, total: 10.2 ms\n",
      "Wall time: 36.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(llm('what is pooling layer?'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
