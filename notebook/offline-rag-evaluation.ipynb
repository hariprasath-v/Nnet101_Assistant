{"cells":[{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:05:41.907510Z","iopub.status.busy":"2024-10-08T12:05:41.907095Z","iopub.status.idle":"2024-10-08T12:05:41.931338Z","shell.execute_reply":"2024-10-08T12:05:41.930310Z","shell.execute_reply.started":"2024-10-08T12:05:41.907470Z"}},"source":["\n","### About\n","#### Generate answers using an LLM from Elastic Search results, and find the cosine similarity between the original answer and the LLM-generated answer.\n","#### Use the LLM as a judge to compare the relevance of original answers and answers generated by the LLM.\n","#### Use the LLM as a judge to compare the relevance of LLM-generated answers to questions."]},{"cell_type":"markdown","metadata":{},"source":["### Import necessary packages and libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:06:43.507935Z","iopub.status.busy":"2024-10-08T12:06:43.507250Z","iopub.status.idle":"2024-10-08T12:06:59.633663Z","shell.execute_reply":"2024-10-08T12:06:59.632368Z","shell.execute_reply.started":"2024-10-08T12:06:43.507892Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install elasticsearch -qq "]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:07:02.993170Z","iopub.status.busy":"2024-10-08T12:07:02.992661Z","iopub.status.idle":"2024-10-08T12:07:16.902229Z","shell.execute_reply":"2024-10-08T12:07:16.900888Z","shell.execute_reply.started":"2024-10-08T12:07:02.993128Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install sentence_transformers==2.7.0 -qq"]},{"cell_type":"code","execution_count":145,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T15:36:06.053464Z","iopub.status.busy":"2024-10-08T15:36:06.052994Z","iopub.status.idle":"2024-10-08T15:36:06.060489Z","shell.execute_reply":"2024-10-08T15:36:06.059213Z","shell.execute_reply.started":"2024-10-08T15:36:06.053419Z"},"trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","import re\n","import io\n","import os\n","import json\n","import requests\n","from tqdm.notebook import tqdm\n","import subprocess\n","import time\n","import json\n","import elasticsearch\n","from elasticsearch import Elasticsearch\n","from sentence_transformers import SentenceTransformer\n","from IPython.display import clear_output"]},{"cell_type":"markdown","metadata":{},"source":["### Get data"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:08:24.102372Z","iopub.status.busy":"2024-10-08T12:08:24.101568Z","iopub.status.idle":"2024-10-08T12:08:25.973065Z","shell.execute_reply":"2024-10-08T12:08:25.971694Z","shell.execute_reply.started":"2024-10-08T12:08:24.102323Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["--2024-10-08 12:08:25--  https://raw.githubusercontent.com/hariprasath-v/Nnet101_Assistant/refs/heads/main/data/nnet_101_qna_with_id.json\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 534194 (522K) [text/plain]\n","Saving to: 'nnet_101_qna_with_id.json'\n","\n","nnet_101_qna_with_i 100%[===================>] 521.67K  --.-KB/s    in 0.1s    \n","\n","2024-10-08 12:08:25 (3.52 MB/s) - 'nnet_101_qna_with_id.json' saved [534194/534194]\n","\n"]}],"source":["!wget https://raw.githubusercontent.com/hariprasath-v/Nnet101_Assistant/refs/heads/main/data/nnet_101_qna_with_id.json"]},{"cell_type":"markdown","metadata":{},"source":["### Load data"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:08:26.258530Z","iopub.status.busy":"2024-10-08T12:08:26.258025Z","iopub.status.idle":"2024-10-08T12:08:26.268990Z","shell.execute_reply":"2024-10-08T12:08:26.267939Z","shell.execute_reply.started":"2024-10-08T12:08:26.258483Z"},"trusted":true},"outputs":[],"source":["with open('nnet_101_qna_with_id.json', 'rt') as f_in:\n","    documents = json.load(f_in)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:08:28.593296Z","iopub.status.busy":"2024-10-08T12:08:28.592857Z","iopub.status.idle":"2024-10-08T12:08:28.602378Z","shell.execute_reply":"2024-10-08T12:08:28.601309Z","shell.execute_reply.started":"2024-10-08T12:08:28.593253Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'question': 'How to choose the number of hidden layers and nodes in a feedforward neural network?',\n"," 'tags': 'model-selection|neural-networks',\n"," 'answer': \"**Network Configuration in Neural Networks**\\n\\n**Standardization**\\nThere is no single standardized method for configuring networks. However, guidelines exist for setting the number and type of network layers, as well as the number of neurons in each layer.\\n\\n**Initial Architecture Setup**\\nBy following specific rules, one can establish a competent network architecture. This involves determining the number and type of neuronal layers and the number of neurons within each layer. This approach provides a foundational architecture but may not be optimal.\\n\\n**Iterative Tuning**\\nOnce the network is initialized, its configuration can be iteratively tuned during training. Ancillary algorithms, such as pruning, can be used to eliminate unnecessary nodes, optimizing the network's size and performance.\\n\\n**Network Layer Types and Sizing**\\nEvery neural network has input, hidden, and output layers.\\n\\n* **Input Layer:** Number of neurons is determined by the number of features in the training data.\\n* **Output Layer:** Number of neurons is determined by the model configuration (regression mode has one node, classification mode uses softmax for multiple classes).\\n* **Hidden Layers:** Number of layers and neurons can be determined empirically, with one hidden layer often being sufficient. Rule of thumb suggests the hidden layer size should be between the input and output layer sizes.\\n\\n**Optimization**\\nPruning techniques can be employed during training to reduce network size and improve performance. This involves identifying and removing nodes that do not significantly impact network performance. Optimizing network configuration can be achieved by initially setting a larger number of neurons and then using pruning to refine the network.\",\n"," 'id': 'f55240b8'}"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["documents[0]"]},{"cell_type":"markdown","metadata":{},"source":["### Load ground truth data"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:08:31.428230Z","iopub.status.busy":"2024-10-08T12:08:31.427645Z","iopub.status.idle":"2024-10-08T12:08:32.040466Z","shell.execute_reply":"2024-10-08T12:08:32.039262Z","shell.execute_reply.started":"2024-10-08T12:08:31.428180Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question</th>\n","      <th>tags</th>\n","      <th>document</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>How do I choose the number of hidden layers in...</td>\n","      <td>model-selection|neural-networks</td>\n","      <td>f55240b8</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>How many nodes should I use in each hidden layer?</td>\n","      <td>model-selection|neural-networks</td>\n","      <td>f55240b8</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>When should I use pruning to optimize network ...</td>\n","      <td>model-selection|neural-networks</td>\n","      <td>f55240b8</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>What is the relationship between the number of...</td>\n","      <td>model-selection|neural-networks</td>\n","      <td>f55240b8</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>How can I determine the optimal network size f...</td>\n","      <td>model-selection|neural-networks</td>\n","      <td>f55240b8</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            question  \\\n","0  How do I choose the number of hidden layers in...   \n","1  How many nodes should I use in each hidden layer?   \n","2  When should I use pruning to optimize network ...   \n","3  What is the relationship between the number of...   \n","4  How can I determine the optimal network size f...   \n","\n","                              tags  document  \n","0  model-selection|neural-networks  f55240b8  \n","1  model-selection|neural-networks  f55240b8  \n","2  model-selection|neural-networks  f55240b8  \n","3  model-selection|neural-networks  f55240b8  \n","4  model-selection|neural-networks  f55240b8  "]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["df_ground_truth_url = 'https://raw.githubusercontent.com/hariprasath-v/Nnet101_Assistant/refs/heads/main/data/ground-truth-data.csv'\n","df_ground_truth=pd.read_csv(df_ground_truth_url)\n","df_ground_truth.head()"]},{"cell_type":"markdown","metadata":{},"source":["### Convert to dictionary"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:08:46.141863Z","iopub.status.busy":"2024-10-08T12:08:46.141398Z","iopub.status.idle":"2024-10-08T12:08:46.166466Z","shell.execute_reply":"2024-10-08T12:08:46.165466Z","shell.execute_reply.started":"2024-10-08T12:08:46.141814Z"},"trusted":true},"outputs":[],"source":["ground_truth = df_ground_truth.to_dict(orient='records')"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:08:47.447930Z","iopub.status.busy":"2024-10-08T12:08:47.447504Z","iopub.status.idle":"2024-10-08T12:08:47.455624Z","shell.execute_reply":"2024-10-08T12:08:47.454434Z","shell.execute_reply.started":"2024-10-08T12:08:47.447889Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'question': 'How do I choose the number of hidden layers in a neural network?',\n"," 'tags': 'model-selection|neural-networks',\n"," 'document': 'f55240b8'}"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["ground_truth[0]"]},{"cell_type":"markdown","metadata":{},"source":["### Collect the document id"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:09:12.128292Z","iopub.status.busy":"2024-10-08T12:09:12.127842Z","iopub.status.idle":"2024-10-08T12:09:12.133732Z","shell.execute_reply":"2024-10-08T12:09:12.132624Z","shell.execute_reply.started":"2024-10-08T12:09:12.128250Z"},"trusted":true},"outputs":[],"source":["doc_idx = {d['id']: d for d in documents}\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:09:13.359033Z","iopub.status.busy":"2024-10-08T12:09:13.358564Z","iopub.status.idle":"2024-10-08T12:09:13.367017Z","shell.execute_reply":"2024-10-08T12:09:13.365731Z","shell.execute_reply.started":"2024-10-08T12:09:13.358981Z"},"trusted":true},"outputs":[{"data":{"text/plain":["\"**Network Configuration in Neural Networks**\\n\\n**Standardization**\\nThere is no single standardized method for configuring networks. However, guidelines exist for setting the number and type of network layers, as well as the number of neurons in each layer.\\n\\n**Initial Architecture Setup**\\nBy following specific rules, one can establish a competent network architecture. This involves determining the number and type of neuronal layers and the number of neurons within each layer. This approach provides a foundational architecture but may not be optimal.\\n\\n**Iterative Tuning**\\nOnce the network is initialized, its configuration can be iteratively tuned during training. Ancillary algorithms, such as pruning, can be used to eliminate unnecessary nodes, optimizing the network's size and performance.\\n\\n**Network Layer Types and Sizing**\\nEvery neural network has input, hidden, and output layers.\\n\\n* **Input Layer:** Number of neurons is determined by the number of features in the training data.\\n* **Output Layer:** Number of neurons is determined by the model configuration (regression mode has one node, classification mode uses softmax for multiple classes).\\n* **Hidden Layers:** Number of layers and neurons can be determined empirically, with one hidden layer often being sufficient. Rule of thumb suggests the hidden layer size should be between the input and output layer sizes.\\n\\n**Optimization**\\nPruning techniques can be employed during training to reduce network size and improve performance. This involves identifying and removing nodes that do not significantly impact network performance. Optimizing network configuration can be achieved by initially setting a larger number of neurons and then using pruning to refine the network.\""]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["doc_idx['f55240b8']['answer']"]},{"cell_type":"markdown","metadata":{},"source":["### Get sentence transformer model"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:09:49.570147Z","iopub.status.busy":"2024-10-08T12:09:49.569655Z","iopub.status.idle":"2024-10-08T12:09:57.430900Z","shell.execute_reply":"2024-10-08T12:09:57.429855Z","shell.execute_reply.started":"2024-10-08T12:09:49.570105Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c1286bcea8764f56b1f8ae6af046529f","version_major":2,"version_minor":0},"text/plain":["modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a8a3e59392fe49ffb7b7dd2fd2a53830","version_major":2,"version_minor":0},"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"71414931a68047379a7a5cb4c593ed5c","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"57d474028fdf4f0b9984d26a4687c7f9","version_major":2,"version_minor":0},"text/plain":["sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f5b20ba9455d4bb08da8b2991baaa82b","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"89149e08065d447d8f49a19deef270ce","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ee05c27ed8264e9e8dc09d67c5df35e1","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a149eb19099643afbd6dac3be0d2ae9b","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9449b96dd77f4c30bb0f6a27a883d003","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"db84815aea284490878c1f36bdec94e8","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b52381ac9d354903901dba41ae3bba12","version_major":2,"version_minor":0},"text/plain":["1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["model_name = 'all-MiniLM-L6-v2'\n","model = SentenceTransformer(model_name)"]},{"cell_type":"markdown","metadata":{},"source":["### Elasticsearch setup"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:11:24.648459Z","iopub.status.busy":"2024-10-08T12:11:24.648011Z","iopub.status.idle":"2024-10-08T12:11:24.656604Z","shell.execute_reply":"2024-10-08T12:11:24.655396Z","shell.execute_reply.started":"2024-10-08T12:11:24.648411Z"},"trusted":true},"outputs":[],"source":["es_client = Elasticsearch('http://localhost:9200/', request_timeout=60) "]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:11:26.277188Z","iopub.status.busy":"2024-10-08T12:11:26.276718Z","iopub.status.idle":"2024-10-08T12:11:27.522103Z","shell.execute_reply":"2024-10-08T12:11:27.520726Z","shell.execute_reply.started":"2024-10-08T12:11:26.277143Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","  \"name\" : \"7ac8f07a9601\",\n","  \"cluster_name\" : \"elasticsearch\",\n","  \"cluster_uuid\" : \"G_AbQeyUQPKBAfuZEeZvgA\",\n","  \"version\" : {\n","    \"number\" : \"8.14.0\",\n","    \"build_flavor\" : \"default\",\n","    \"build_type\" : \"tar\",\n","    \"build_hash\" : \"8d96bbe3bf5fed931f3119733895458eab75dca9\",\n","    \"build_date\" : \"2024-06-03T10:05:49.073003402Z\",\n","    \"build_snapshot\" : false,\n","    \"lucene_version\" : \"9.10.0\",\n","    \"minimum_wire_compatibility_version\" : \"7.17.0\",\n","    \"minimum_index_compatibility_version\" : \"7.0.0\"\n","  },\n","  \"tagline\" : \"You Know, for Search\"\n","}\n"]}],"source":["!curl localhost:9200"]},{"cell_type":"markdown","metadata":{},"source":["### Create index and to elasticsearch"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:12:21.606164Z","iopub.status.busy":"2024-10-08T12:12:21.604720Z","iopub.status.idle":"2024-10-08T12:12:22.597551Z","shell.execute_reply":"2024-10-08T12:12:22.593894Z","shell.execute_reply.started":"2024-10-08T12:12:21.606092Z"},"trusted":true},"outputs":[{"data":{"text/plain":["ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'nnet101'})"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["index_settings = {\n","    \"settings\": {\n","        \"number_of_shards\": 1,\n","        \"number_of_replicas\": 0\n","    },\n","    \"mappings\": {\n","        \"properties\": {\n","            \"answer\": {\"type\": \"text\"},\n","            \"question\": {\"type\": \"text\"},\n","            \"tags\": {\"type\": \"keyword\"},\n","            \"id\": {\"type\": \"keyword\"},\n","            \"question_answer_vector\": {\n","                \"type\": \"dense_vector\",\n","                \"dims\": 384,\n","                \"index\": True,\n","                \"similarity\": \"cosine\"\n","            },\n","        }\n","    }\n","}\n","\n","index_name = \"nnet101\"\n","\n","es_client.indices.delete(index=index_name, ignore_unavailable=True)\n","es_client.indices.create(index=index_name, body=index_settings)"]},{"cell_type":"markdown","metadata":{},"source":["### Combine question and answer, and encode."]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:13:57.281548Z","iopub.status.busy":"2024-10-08T12:13:57.280195Z","iopub.status.idle":"2024-10-08T12:14:38.901084Z","shell.execute_reply":"2024-10-08T12:14:38.899942Z","shell.execute_reply.started":"2024-10-08T12:13:57.281491Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"df03f81af61141488ee5b1f9ba1bae22","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/500 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from tqdm.auto import tqdm\n","\n","for doc in tqdm(documents):\n","    question = doc['question']\n","    answer = doc['answer']\n","    doc['question_answer_vector'] = model.encode(question + ' ' + answer, show_progress_bar=False)\n","\n","    es_client.index(index=index_name, document=doc)"]},{"cell_type":"markdown","metadata":{},"source":["## Retrieval"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:15:12.258818Z","iopub.status.busy":"2024-10-08T12:15:12.257596Z","iopub.status.idle":"2024-10-08T12:15:12.266201Z","shell.execute_reply":"2024-10-08T12:15:12.264721Z","shell.execute_reply.started":"2024-10-08T12:15:12.258742Z"},"trusted":true},"outputs":[],"source":["def elastic_search_knn(field, vector):\n","    knn = {\n","        \"field\": field,\n","        \"query_vector\": vector,\n","        \"k\": 5,\n","        \"num_candidates\": 10000,\n","        \n","    }\n","\n","    search_query = {\n","        \"knn\": knn,\n","        \"_source\": [\"answer\", \"tags\", \"question\", \"id\"]\n","    }\n","\n","    es_results = es_client.search(\n","        index=index_name,\n","        body=search_query\n","    )\n","    \n","    result_docs = []\n","    \n","    for hit in es_results['hits']['hits']:\n","        result_docs.append(hit['_source'])\n","\n","    return result_docs\n"]},{"cell_type":"markdown","metadata":{},"source":["### Function to embed a question and answer, and return the result based on the question and asnwer vector."]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:15:15.370114Z","iopub.status.busy":"2024-10-08T12:15:15.369666Z","iopub.status.idle":"2024-10-08T12:15:15.376438Z","shell.execute_reply":"2024-10-08T12:15:15.374933Z","shell.execute_reply.started":"2024-10-08T12:15:15.370074Z"},"trusted":true},"outputs":[],"source":["def question_text_vector_knn(q):\n","    question = q['question']\n","   \n","\n","    v_q = model.encode(question, show_progress_bar=False)\n","\n","    return elastic_search_knn('question_answer_vector', v_q,)"]},{"cell_type":"markdown","metadata":{},"source":["### Sample search"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:15:27.410486Z","iopub.status.busy":"2024-10-08T12:15:27.410064Z","iopub.status.idle":"2024-10-08T12:15:28.030917Z","shell.execute_reply":"2024-10-08T12:15:28.029576Z","shell.execute_reply.started":"2024-10-08T12:15:27.410447Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[{'question': 'What is global max pooling layer and what is its advantage over maxpooling layer?',\n","  'tags': 'neural-networks|convolutional-neural-network|pooling',\n","  'answer': '**Summary:**\\n\\nGlobal max pooling is a type of max pooling where the pool size is equal to the input size. Unlike regular max pooling, which produces a smaller output, global max pooling produces an output with the same dimensionality as the input.\\n\\nIn global max pooling, the maximum value across the entire input is extracted, providing a representation that focuses on the most prominent feature. This is useful in applications like natural language processing, where the most important words in a sentence are often indicative of its meaning.\\n\\nIn contrast, regular max pooling divides the input into smaller segments and extracts the maximum value from each segment, reducing the output size. This is more common in computer vision, where spatial information is important and reducing the size of the representation can be beneficial for computational efficiency.',\n","  'id': '26cf9a0d'},\n"," {'question': 'Difference between pooling and subsampling',\n","  'tags': 'neural-networks|convolutional-neural-network|computer-vision',\n","  'answer': '**Summary:**\\n\\nPooling layers in convolutional neural networks (CNNs) perform a form of subsampling that reduces the dimensionality of the input data. This process of reducing the size of the data while retaining its essential features is known as subsampling.\\n\\nThe paper \"Gradient-Based Learning Applied to Document Recognition\" by Yann LeCun refers to subsampling as a pooling layer. This suggests that pooling layers can be used to perform subsampling operations in CNNs.\\n\\nIn essence, pooling operations are a type of subsampling that reduce the size of the image while preserving its important characteristics. This makes them a crucial component in CNNs for efficiently extracting features from images.',\n","  'id': 'ee5ac3e7'},\n"," {'question': 'Feature extracted by max pooling vs mean pooling',\n","  'tags': 'machine-learning|deep-learning|feature-engineering|computer-vision',\n","  'answer': 'Convolutional layers extract features from input data, while pooling layers compress these features to reduce dimensionality. There are two main types of pooling layers: max-pooling and mean-pooling.\\n\\n**Max-pooling** selects the maximum activation value within a block of data, prioritizing the presence of a specific feature in a general area. However, it can lose information about low activations within that block.\\n\\n**Mean-pooling** calculates the average activation value within a block, which can smooth out large activations. It retains some information about low activations but may not capture the presence of specific features as strongly as max-pooling.\\n\\nThe choice between max-pooling and mean-pooling depends on the desired level of feature extraction and the importance of preserving low activation information.',\n","  'id': 'c6845dad'},\n"," {'question': 'Why is max pooling necessary in convolutional neural networks?',\n","  'tags': 'deep-learning|convolutional-neural-network|pooling',\n","  'answer': '**Summary:**\\n\\nPooling layers in convolutional neural networks (CNNs) offer some translation invariance and computational efficiency. However, they can be replaced by convolutions with stride, which may yield superior results.\\n\\nSome recent CNN architectures, such as Wide Residual Networks and DenseNets, employ average pooling. Others, like DelugeNets, utilize convolutions with stride. The optimal choice between pooling and convolutions can vary depending on the network architecture and task.\\n\\nOverall, the use of convolutions with stride can be a viable alternative to pooling layers in CNNs, offering the potential for enhanced performance.',\n","  'id': 'ad06a5ac'},\n"," {'question': 'Minimum number of layers in a deep neural network',\n","  'tags': 'machine-learning|neural-networks|deep-learning|terminology',\n","  'answer': 'The term \"deep\" has become a marketing buzzword associated with multi-layered neural networks, a type of artificial intelligence architecture. This terminology is employed to enhance the marketability of such networks.',\n","  'id': '60daac19'}]"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["question_text_vector_knn({'question':\n","    'what is pooling layer?'}\n","    )"]},{"cell_type":"markdown","metadata":{},"source":["## The RAG flow"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:20:33.253064Z","iopub.status.busy":"2024-10-08T12:20:33.252251Z","iopub.status.idle":"2024-10-08T12:20:33.260066Z","shell.execute_reply":"2024-10-08T12:20:33.258722Z","shell.execute_reply.started":"2024-10-08T12:20:33.253021Z"},"trusted":true},"outputs":[],"source":["def build_prompt(query, search_results):\n","    prompt_template = \"\"\"\n","You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n","Use only the facts from the CONTEXT when answering the QUESTION.\n","\n","QUESTION: {question}\n","\n","CONTEXT: \n","{context}\n","\"\"\".strip()\n","\n","    context = \"\"\n","    \n","    for doc in search_results:\n","        context = context + f\"tags: {doc['tags']}\\nquestion: {doc['question']}\\nanswer: {doc['answer']}\\n\\n\"\n","    \n","    prompt = prompt_template.format(question=query, context=context).strip()\n","    return prompt"]},{"cell_type":"markdown","metadata":{},"source":["### Cloudflare network Workers AI configuration"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:18:53.839320Z","iopub.status.busy":"2024-10-08T12:18:53.838105Z","iopub.status.idle":"2024-10-08T12:19:07.702120Z","shell.execute_reply":"2024-10-08T12:19:07.700987Z","shell.execute_reply.started":"2024-10-08T12:18:53.839272Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'result': {'response': 'PEP 8, also known as the Python Enhancement Proposal 8, is a style guide for writing Python code. It was written by Guido van Rossum, the creator of the Python programming language, to provide a set of best practices for writing Python code.\\n\\nPEP 8 was first published in 2001 and has since become an essential reference for Python developers. The guide covers a range of topics, including:\\n\\n1. **Indentation**: PEP 8 recommends using 4 spaces for indentation, and discouraged the use of tabs.\\n2. **Naming conventions**: It provides guidelines for naming variables, functions, classes, and modules, including the use of underscores to separate words and lowercase letters for variable names.\\n3. **Code layout**: It recommends consistent line lengths, consistent indentation, and the use of blank lines to separate logical sections of code.\\n4. **Comments**: PEP 8 provides recommendations for commenting code, including the use of docstrings and inline comments.\\n5. **Error handling**: It discusses the principles of good error handling, including the use of try-except blocks and error messages.\\n6. **Internationalization**: It provides guidelines for internationalizing Python code, including the use of Unicode and localization.\\n7. **Semantic versioning**: It discusses the concept of semantic versioning and how it can be used to manage dependencies and releases.\\n\\nSome of the key principles outlined in PEP 8 include:\\n\\n* **Consistency**: Consistency in naming conventions, indentation, and code style is essential for readability and maintainability.\\n* **Readability**: Code should be written to be easy to read and understand, with clear and concise variable names, comments, and whitespace.\\n* **Minimize clutter**: Code should be kept simple and free of unnecessary complexity, with a focus on clarity and brevity.\\n* **Keep it simple**: Code should be designed to be simple to understand and maintain, with a focus on clarity and ease of use.\\n\\nBy following the guidelines outlined in PEP 8, developers can write Python code that is clear, concise, and easy to maintain. While PEP 8 is not a mandatory standard, it is widely adopted and respected within the Python community, and is an essential resource for any Python developer.\\n\\nHere are some of the most important takeaways from PEP 8:\\n\\n1. Use 4 spaces for indentation.\\n2. Use underscores to separate words in variable names.\\n3. Use lowercase letters for variable names.\\n4. Use consistent line lengths and consistent indentation.\\n5.'},\n"," 'success': True,\n"," 'errors': [],\n"," 'messages': []}"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["\n","ACCOUNT_ID = \"acc_id\"\n","AUTH_TOKEN = \"token\"\n","\n","prompt = \"Tell me all about PEP-8\"\n","response = requests.post(\n","  f\"https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/ai/run/@cf/meta/llama-2-7b-chat-int8\",\n","    headers={\"Authorization\": f\"Bearer {AUTH_TOKEN}\"},\n","    json={\n","      \"messages\": [\n","        {\"role\": \"user\", \"content\": prompt}\n","      ]\n","    }\n",")\n","result = response.json()\n","result"]},{"cell_type":"markdown","metadata":{},"source":["### Workers AI - llama-2-7b-chat-int8 model"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:44:34.994074Z","iopub.status.busy":"2024-10-08T12:44:34.993167Z","iopub.status.idle":"2024-10-08T12:44:35.000316Z","shell.execute_reply":"2024-10-08T12:44:34.999118Z","shell.execute_reply.started":"2024-10-08T12:44:34.994023Z"},"trusted":true},"outputs":[],"source":["def llm(prompt, model='meta/llama-2-7b-chat-int8'):\n","    response = requests.post(\n","      f\"https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/ai/run/@cf/{model}\",\n","    headers={\"Authorization\": f\"Bearer {AUTH_TOKEN}\"},\n","    json={\n","      \"messages\": [\n","        {\"role\": \"user\", \"content\": prompt}\n","      ]\n","        }\n","    )\n","    result = response.json()\n","    return result"]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:44:31.834830Z","iopub.status.busy":"2024-10-08T12:44:31.834330Z","iopub.status.idle":"2024-10-08T12:44:31.841034Z","shell.execute_reply":"2024-10-08T12:44:31.839849Z","shell.execute_reply.started":"2024-10-08T12:44:31.834768Z"},"trusted":true},"outputs":[],"source":["def rag(query,model='meta/llama-2-7b-chat-int8'):\n","    search_results = question_text_vector_knn(query)\n","    prompt = build_prompt(query['question'], search_results)\n","    answer = llm(prompt,model)\n","    return answer"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:20:14.467996Z","iopub.status.busy":"2024-10-08T12:20:14.467507Z","iopub.status.idle":"2024-10-08T12:20:14.475898Z","shell.execute_reply":"2024-10-08T12:20:14.474585Z","shell.execute_reply.started":"2024-10-08T12:20:14.467950Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'question': 'What are keys, queries, and values in attention mechanisms?',\n"," 'tags': 'neural-networks|natural-language|attention|machine-translation',\n"," 'document': 'bac0222f'}"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["ground_truth[10]"]},{"cell_type":"markdown","metadata":{},"source":["### LLM answer"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:42:08.633216Z","iopub.status.busy":"2024-10-08T12:42:08.632705Z","iopub.status.idle":"2024-10-08T12:42:15.010739Z","shell.execute_reply":"2024-10-08T12:42:15.009224Z","shell.execute_reply.started":"2024-10-08T12:42:08.633171Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'result': {'response': \"Based on the provided CONTEXT, here's the answer to the QUESTION:\\n\\nIn attention mechanisms, keys, queries, and values are used as follows:\\n\\n* The query represents the input to be matched.\\n* The keys store the candidate matches.\\n* The values store the information associated with each key.\\n* The query is matched against the keys to retrieve the relevant values, which are then weighted by a probability vector alpha to produce the final output.\\n\\nIn other words, the keys, queries, and values are used together to compute attention weights that determine how much information from each key-value pair should be included in the final output.\"}, 'success': True, 'errors': [], 'messages': []}\n"]}],"source":["print(rag(ground_truth[10]))"]},{"cell_type":"markdown","metadata":{},"source":["### Original answer"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:20:48.898199Z","iopub.status.busy":"2024-10-08T12:20:48.897742Z","iopub.status.idle":"2024-10-08T12:20:48.907916Z","shell.execute_reply":"2024-10-08T12:20:48.906713Z","shell.execute_reply.started":"2024-10-08T12:20:48.898159Z"},"trusted":true},"outputs":[{"data":{"text/plain":["\"In the key/value/query formulation of attention, the query represents the input to be matched, while the keys and values store the candidate matches and their associated information.\\nLike a search engine, attention's query is matched against a set of keys, and the best matched values are returned.\\nThis retrieval process involves calculating a probability vector alpha, which determines the proportion of each value to include in the output.\\n\\nThe first paper (Bahdanau et al. 2015) calculates alpha using a neural network, which is computationally expensive.\\nThe second paper (Vaswani et al. 2017) proposes a more efficient approach, where the keys and values are first projected onto a common space, and then a similarity measure is used to calculate alpha.\\nThis approach corresponds to the retrieval system concept, where the query and key projections are analogous to the user query and video metadata, respectively.\\n\\nMultihead attention extends this key/value/query formulation by splitting the inputs into multiple heads and applying attention to each head independently.\\nThe outputs of each head are then concatenated to produce the final attention output.\\n\\nThe source of the queries, keys, and values depends on the application.\\nFor self-attention (as in language models), they all come from the same source.\\nFor tasks like machine translation, queries and keys can come from different sources (e.g., target and source sequences, respectively).\\nIn recommendation systems, queries can represent target items, while keys and values can represent user profiles and history.\""]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["doc_idx['bac0222f']['answer']"]},{"cell_type":"markdown","metadata":{},"source":["### Cosine similarity metric"]},{"cell_type":"code","execution_count":66,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:42:35.410191Z","iopub.status.busy":"2024-10-08T12:42:35.409715Z","iopub.status.idle":"2024-10-08T12:42:35.418380Z","shell.execute_reply":"2024-10-08T12:42:35.417252Z","shell.execute_reply.started":"2024-10-08T12:42:35.410147Z"},"trusted":true},"outputs":[],"source":["answer_orig = \"In the key/value/query formulation of attention, the query represents the input to be matched, while the keys and values store the candidate matches and their associated information.\\nLike a search engine, attention's query is matched against a set of keys, and the best matched values are returned.\\nThis retrieval process involves calculating a probability vector alpha, which determines the proportion of each value to include in the output.\\n\\nThe first paper (Bahdanau et al. 2015) calculates alpha using a neural network, which is computationally expensive.\\nThe second paper (Vaswani et al. 2017) proposes a more efficient approach, where the keys and values are first projected onto a common space, and then a similarity measure is used to calculate alpha.\\nThis approach corresponds to the retrieval system concept, where the query and key projections are analogous to the user query and video metadata, respectively.\\n\\nMultihead attention extends this key/value/query formulation by splitting the inputs into multiple heads and applying attention to each head independently.\\nThe outputs of each head are then concatenated to produce the final attention output.\\n\\nThe source of the queries, keys, and values depends on the application.\\nFor self-attention (as in language models), they all come from the same source.\\nFor tasks like machine translation, queries and keys can come from different sources (e.g., target and source sequences, respectively).\\nIn recommendation systems, queries can represent target items, while keys and values can represent user profiles and history.\"\n"]},{"cell_type":"code","execution_count":67,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:42:49.749327Z","iopub.status.busy":"2024-10-08T12:42:49.748876Z","iopub.status.idle":"2024-10-08T12:42:49.877919Z","shell.execute_reply":"2024-10-08T12:42:49.876913Z","shell.execute_reply.started":"2024-10-08T12:42:49.749288Z"},"trusted":true},"outputs":[],"source":["answer_llm = \"\"\"Based on the provided CONTEXT, here's the answer to the QUESTION:\\n\\nIn attention mechanisms, keys, queries, and values are used as follows:\\n\\n* The query represents the input to be matched.\\n* The keys store the candidate matches.\\n* The values store the information associated with each key.\\n* The query is matched against the keys to retrieve the relevant values, which are then weighted by a probability vector alpha to produce the final output.\\n\\nIn other words, the keys, queries, and values are used together to compute attention weights that determine how much information from each key-value pair should be included in the final output\"\"\"\n","\n","\n","v_llm = model.encode(answer_llm, show_progress_bar=False)\n","v_orig = model.encode(answer_orig,show_progress_bar=False)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### Sample similarity score"]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:43:07.178215Z","iopub.status.busy":"2024-10-08T12:43:07.177360Z","iopub.status.idle":"2024-10-08T12:43:07.185280Z","shell.execute_reply":"2024-10-08T12:43:07.184059Z","shell.execute_reply.started":"2024-10-08T12:43:07.178166Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0.748703"]},"execution_count":68,"metadata":{},"output_type":"execute_result"}],"source":["v_llm.dot(v_orig)"]},{"cell_type":"markdown","metadata":{},"source":["### Generate answer for ground truth data"]},{"cell_type":"code","execution_count":103,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T08:00:58.988202Z","iopub.status.busy":"2024-10-08T08:00:58.987279Z","iopub.status.idle":"2024-10-08T08:17:33.193655Z","shell.execute_reply":"2024-10-08T08:17:33.192656Z","shell.execute_reply.started":"2024-10-08T08:00:58.988157Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 2500/2500 [16:34<00:00,  2.51it/s]\n"]}],"source":["from concurrent.futures import ThreadPoolExecutor, as_completed\n","from tqdm import tqdm\n","\n","def process_record(i, rec, doc_idx):\n","    answer_llm = rag(rec)\n","    doc_id = rec['document']\n","    original_doc = doc_idx[doc_id]\n","    answer_orig = original_doc['answer']\n","    \n","    return i, {\n","        'answer_llm': answer_llm,\n","        'answer_orig': answer_orig,\n","        'document': doc_id,\n","        'question': rec['question'],\n","        'tags': rec['tags'],\n","    }\n","\n","# Dictionary to store results\n","answers = {}\n","\n","# ThreadPoolExecutor for parallel processing\n","with ThreadPoolExecutor() as executor:\n","    futures = [\n","        executor.submit(process_record, i, rec, doc_idx)\n","        for i, rec in enumerate(ground_truth) if i not in answers\n","    ]\n","\n","    # Collect results as they complete\n","    for future in tqdm(as_completed(futures), total=len(futures)):\n","        i, result = future.result()\n","        answers[i] = result\n"]},{"cell_type":"markdown","metadata":{},"source":["### Create dataframe"]},{"cell_type":"code","execution_count":106,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T08:20:08.569058Z","iopub.status.busy":"2024-10-08T08:20:08.568602Z","iopub.status.idle":"2024-10-08T08:20:08.579595Z","shell.execute_reply":"2024-10-08T08:20:08.578489Z","shell.execute_reply.started":"2024-10-08T08:20:08.569023Z"},"trusted":true},"outputs":[],"source":["results_llama_2_7b_chat_int8 = [None] * len(ground_truth)\n","\n","for i, val in answers.items():\n","    results_llama_2_7b_chat_int8[i] = val.copy()\n","    results_llama_2_7b_chat_int8[i].update(ground_truth[i])"]},{"cell_type":"code","execution_count":108,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T08:20:58.277632Z","iopub.status.busy":"2024-10-08T08:20:58.277158Z","iopub.status.idle":"2024-10-08T08:20:58.286831Z","shell.execute_reply":"2024-10-08T08:20:58.285704Z","shell.execute_reply.started":"2024-10-08T08:20:58.277594Z"},"trusted":true},"outputs":[],"source":["results_llama_2_7b_chat_int8_df = pd.DataFrame(results_llama_2_7b_chat_int8)"]},{"cell_type":"code","execution_count":123,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T08:24:03.966773Z","iopub.status.busy":"2024-10-08T08:24:03.965646Z","iopub.status.idle":"2024-10-08T08:24:03.976364Z","shell.execute_reply":"2024-10-08T08:24:03.975355Z","shell.execute_reply.started":"2024-10-08T08:24:03.966718Z"},"trusted":true},"outputs":[],"source":["results_llama_2_7b_chat_int8_df['answer_llm'] = results_llama_2_7b_chat_int8_df['answer_llm'].apply(lambda x:x['result']['response'])"]},{"cell_type":"markdown","metadata":{},"source":["### Compute similarity score for the entire document"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:32:00.704660Z","iopub.status.busy":"2024-10-08T12:32:00.703724Z","iopub.status.idle":"2024-10-08T12:32:00.711333Z","shell.execute_reply":"2024-10-08T12:32:00.710051Z","shell.execute_reply.started":"2024-10-08T12:32:00.704611Z"},"trusted":true},"outputs":[],"source":["def compute_similarity(record):\n","    answer_orig = record['answer_orig']\n","    answer_llm = record['answer_llm']\n","    \n","    v_llm = model.encode(answer_llm , show_progress_bar=False)\n","    v_orig = model.encode(answer_orig, show_progress_bar=False)\n","    \n","    return v_llm.dot(v_orig)"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:32:06.260507Z","iopub.status.busy":"2024-10-08T12:32:06.260079Z","iopub.status.idle":"2024-10-08T12:35:49.678226Z","shell.execute_reply":"2024-10-08T12:35:49.677162Z","shell.execute_reply.started":"2024-10-08T12:32:06.260468Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"60515280127946789d6756f399c99c62","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2500 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["similarity = []\n","\n","for record in tqdm(results_llama_2_7b_chat_int8_df.to_dict(orient='records')):\n","    sim = compute_similarity(record)\n","    similarity.append(sim)"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:36:25.996874Z","iopub.status.busy":"2024-10-08T12:36:25.995549Z","iopub.status.idle":"2024-10-08T12:36:26.015507Z","shell.execute_reply":"2024-10-08T12:36:26.014211Z","shell.execute_reply.started":"2024-10-08T12:36:25.996823Z"},"trusted":true},"outputs":[{"data":{"text/plain":["count    2500.000000\n","mean        0.675582\n","std         0.161148\n","min        -0.020848\n","25%         0.582057\n","50%         0.705028\n","75%         0.792661\n","max         0.981918\n","Name: cosine, dtype: float64"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["results_llama_2_7b_chat_int8_df['cosine'] = similarity\n","results_llama_2_7b_chat_int8_df['cosine'].describe()"]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:37:16.327429Z","iopub.status.busy":"2024-10-08T12:37:16.326977Z","iopub.status.idle":"2024-10-08T12:37:16.625097Z","shell.execute_reply":"2024-10-08T12:37:16.623763Z","shell.execute_reply.started":"2024-10-08T12:37:16.327387Z"},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["pd.Series(similarity).plot(kind='hist');"]},{"cell_type":"markdown","metadata":{},"source":["### Save dataframe"]},{"cell_type":"code","execution_count":80,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T14:49:05.928542Z","iopub.status.busy":"2024-10-08T14:49:05.927374Z","iopub.status.idle":"2024-10-08T14:49:06.117637Z","shell.execute_reply":"2024-10-08T14:49:06.116590Z","shell.execute_reply.started":"2024-10-08T14:49:05.928492Z"},"trusted":true},"outputs":[],"source":["results_llama_2_7b_chat_int8_df.to_csv(\"llm_answers_llama_2_7b_chat_int8.csv\",index=False)"]},{"cell_type":"markdown","metadata":{},"source":["## Workers AI - mistral-7b-instruct-v0.1"]},{"cell_type":"code","execution_count":78,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T12:49:15.518337Z","iopub.status.busy":"2024-10-08T12:49:15.517881Z","iopub.status.idle":"2024-10-08T13:50:42.388682Z","shell.execute_reply":"2024-10-08T13:50:42.387217Z","shell.execute_reply.started":"2024-10-08T12:49:15.518295Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 2500/2500 [1:01:26<00:00,  1.47s/it]\n"]}],"source":["def process_record(i, rec, doc_idx):\n","    answer_llm = rag(rec,model=\"/mistral/mistral-7b-instruct-v0.1\")\n","    doc_id = rec['document']\n","    original_doc = doc_idx[doc_id]\n","    answer_orig = original_doc['answer']\n","    \n","    return i, {\n","        'answer_llm': answer_llm,\n","        'answer_orig': answer_orig,\n","        'document': doc_id,\n","        'question': rec['question'],\n","        'tags': rec['tags'],\n","    }\n","\n","# Dictionary to store results\n","answers_new = {}\n","\n","# ThreadPoolExecutor for parallel processing\n","with ThreadPoolExecutor() as executor:\n","    futures = [\n","        executor.submit(process_record, i, rec, doc_idx)\n","        for i, rec in enumerate(ground_truth) if i not in answers_new\n","    ]\n","\n","    # Collect results as they complete\n","    for future in tqdm(as_completed(futures), total=len(futures)):\n","        i, result = future.result()\n","        answers_new[i] = result\n"]},{"cell_type":"markdown","metadata":{},"source":["### Create dataframe"]},{"cell_type":"code","execution_count":81,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T14:51:17.470532Z","iopub.status.busy":"2024-10-08T14:51:17.469399Z","iopub.status.idle":"2024-10-08T14:51:17.481951Z","shell.execute_reply":"2024-10-08T14:51:17.480630Z","shell.execute_reply.started":"2024-10-08T14:51:17.470485Z"},"trusted":true},"outputs":[],"source":["mistral_7b_instruct_v0_1 = [None] * len(ground_truth)\n","\n","for i, val in answers_new.items():\n","    mistral_7b_instruct_v0_1[i] = val.copy()\n","    mistral_7b_instruct_v0_1[i].update(ground_truth[i])"]},{"cell_type":"code","execution_count":82,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T14:51:20.447058Z","iopub.status.busy":"2024-10-08T14:51:20.446589Z","iopub.status.idle":"2024-10-08T14:51:20.457898Z","shell.execute_reply":"2024-10-08T14:51:20.456572Z","shell.execute_reply.started":"2024-10-08T14:51:20.447006Z"},"trusted":true},"outputs":[],"source":["mistral_7b_instruct_v0_1_df = pd.DataFrame(mistral_7b_instruct_v0_1)"]},{"cell_type":"code","execution_count":86,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T14:52:27.881419Z","iopub.status.busy":"2024-10-08T14:52:27.880344Z","iopub.status.idle":"2024-10-08T14:52:27.893444Z","shell.execute_reply":"2024-10-08T14:52:27.892281Z","shell.execute_reply.started":"2024-10-08T14:52:27.881369Z"},"trusted":true},"outputs":[],"source":[" mistral_7b_instruct_v0_1_df['answer_llm'] = mistral_7b_instruct_v0_1_df['answer_llm'].apply(lambda x: x['result']['response'])"]},{"cell_type":"markdown","metadata":{},"source":["### Calculate similarity"]},{"cell_type":"code","execution_count":87,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T14:53:33.133482Z","iopub.status.busy":"2024-10-08T14:53:33.133025Z","iopub.status.idle":"2024-10-08T14:58:00.461690Z","shell.execute_reply":"2024-10-08T14:58:00.460358Z","shell.execute_reply.started":"2024-10-08T14:53:33.133441Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 2500/2500 [04:27<00:00,  9.35it/s]\n"]}],"source":["similarity_new = []\n","\n","for record in tqdm(mistral_7b_instruct_v0_1_df.to_dict(orient='records')):\n","    sim = compute_similarity(record)\n","    similarity_new.append(sim)"]},{"cell_type":"code","execution_count":88,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T14:58:20.524090Z","iopub.status.busy":"2024-10-08T14:58:20.522969Z","iopub.status.idle":"2024-10-08T14:58:20.539956Z","shell.execute_reply":"2024-10-08T14:58:20.538851Z","shell.execute_reply.started":"2024-10-08T14:58:20.524036Z"},"trusted":true},"outputs":[{"data":{"text/plain":["count    2500.000000\n","mean        0.709169\n","std         0.157913\n","min        -0.068219\n","25%         0.621302\n","50%         0.741953\n","75%         0.825930\n","max         0.986987\n","Name: cosine, dtype: float64"]},"execution_count":88,"metadata":{},"output_type":"execute_result"}],"source":["mistral_7b_instruct_v0_1_df['cosine'] = similarity_new\n","mistral_7b_instruct_v0_1_df['cosine'].describe()"]},{"cell_type":"code","execution_count":89,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T14:58:25.802614Z","iopub.status.busy":"2024-10-08T14:58:25.802079Z","iopub.status.idle":"2024-10-08T14:58:26.100604Z","shell.execute_reply":"2024-10-08T14:58:26.099425Z","shell.execute_reply.started":"2024-10-08T14:58:25.802568Z"},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["pd.Series(similarity_new).plot(kind='hist');"]},{"cell_type":"code","execution_count":90,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T14:58:30.226889Z","iopub.status.busy":"2024-10-08T14:58:30.225983Z","iopub.status.idle":"2024-10-08T14:58:30.452241Z","shell.execute_reply":"2024-10-08T14:58:30.451152Z","shell.execute_reply.started":"2024-10-08T14:58:30.226837Z"},"trusted":true},"outputs":[],"source":["mistral_7b_instruct_v0_1_df.to_csv(\"llm_answers_mistral_7b_instruct_v0_1.csv\",index=False)"]},{"cell_type":"markdown","metadata":{},"source":["### LLM-as-a-Judge"]},{"cell_type":"code","execution_count":97,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T15:07:36.937591Z","iopub.status.busy":"2024-10-08T15:07:36.936594Z","iopub.status.idle":"2024-10-08T15:07:36.943986Z","shell.execute_reply":"2024-10-08T15:07:36.942845Z","shell.execute_reply.started":"2024-10-08T15:07:36.937547Z"},"trusted":true},"outputs":[],"source":["prompt1_template = \"\"\"\n","You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n","Your task is to analyze the relevance of the generated answer compared to the original answer provided.\n","Based on the relevance and similarity of the generated answer to the original answer, you will classify\n","it as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n","\n","Here is the data for evaluation:\n","\n","Original Answer: {answer_orig}\n","Generated Question: {question}\n","Generated Answer: {answer_llm}\n","\n","Please analyze the content and context of the generated answer in relation to the original\n","answer and provide your evaluation in parsable JSON without using code blocks:\n","\n","{{\n","  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n","  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n","}}\n","\"\"\".strip()\n","\n","prompt2_template = \"\"\"\n","You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n","Your task is to analyze the relevance of the generated answer to the given question.\n","Based on the relevance of the generated answer, you will classify it\n","as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n","\n","Here is the data for evaluation:\n","\n","Question: {question}\n","Generated Answer: {answer_llm}\n","\n","Please analyze the content and context of the generated answer in relation to the question\n","and provide your evaluation in parsable JSON without using code blocks:\n","\n","{{\n","  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n","  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n","}}\n","\"\"\".strip()"]},{"cell_type":"markdown","metadata":{},"source":["### Llma Evaluation"]},{"cell_type":"code","execution_count":92,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T15:07:09.865562Z","iopub.status.busy":"2024-10-08T15:07:09.865136Z","iopub.status.idle":"2024-10-08T15:07:09.880980Z","shell.execute_reply":"2024-10-08T15:07:09.879567Z","shell.execute_reply.started":"2024-10-08T15:07:09.865523Z"},"trusted":true},"outputs":[],"source":["df_sample_llama = results_llama_2_7b_chat_int8_df.sample(n=150, random_state=1)"]},{"cell_type":"code","execution_count":93,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T15:07:19.451404Z","iopub.status.busy":"2024-10-08T15:07:19.450935Z","iopub.status.idle":"2024-10-08T15:07:19.459654Z","shell.execute_reply":"2024-10-08T15:07:19.458178Z","shell.execute_reply.started":"2024-10-08T15:07:19.451343Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["df_sample_llama = df_sample_llama.to_dict(orient='records')"]},{"cell_type":"code","execution_count":95,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T15:07:25.287270Z","iopub.status.busy":"2024-10-08T15:07:25.286651Z","iopub.status.idle":"2024-10-08T15:07:25.296592Z","shell.execute_reply":"2024-10-08T15:07:25.295286Z","shell.execute_reply.started":"2024-10-08T15:07:25.287213Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'answer_llm': 'According to the context, SNNs (Spiking Neural Networks) are not mentioned in the provided context. However, the question asks how SNNs differ from previous neural network models. Since SNNs are not mentioned, we cannot provide a direct answer. \\n\\nIf the question was rephrased to ask about the differences between previous neural network models, the answer would be that the context mentions various types of neural networks, including:\\n\\n1. Perceptrons: A specific type of neural network introduced by Rosenblatt in 1957.\\n2. Multi-Layered Perceptron (MLP): A type of feed-forward neural network with layers of fully connected nodes.\\n3. Recurrent Neural Networks (RNNs): Neural networks with undirected loops within layers, providing storage capacity.\\n4. Hopfield Network: A type of neural network with a single interconnected layer and binary nodes.\\n5. Restricted Boltzmann Machines (RBMs): Two-layer models with visible and hidden units.\\n6. Convolutional Neural Networks (CNNs): Deep learning models using convolutional filters to process image data.\\n7. Deep Belief Networks (DBNs): Neural networks with undirected connections between some layers.\\n8. Deep Neural Networks (DNNs): Feedforward networks with multiple hidden layers.\\n\\nThese neural network models differ in their architecture, training algorithms, and applications.',\n"," 'answer_orig': '**Summary:**\\n\\nUnderstanding neural networks, including their structure and function, remains a significant challenge. The field has progressed through three key models:\\n\\n* **Perceptron Model:** Can compute any boolean function using a multilayer perceptron with a hidden layer.\\n* **Neuron Model:** An improved version using sigmoid activation, capable of computing any boolean function and approximating continuous functions.\\n* **Spiking Neurons Model:** Incorporates temporal coding to pass information, allowing for more efficient computation than the previous models and a closer fidelity to the human brain.\\n\\nIn practice, Spiking Neural Networks (SNNs) show promise, as evidenced by commercial products like SpikeNET. However, challenges arise from the inherent complexity of SNNs, including the need to define information coding methods and emulate biological learning mechanisms.\\n\\nResearchers are exploring various coding techniques to represent information in SNNs, such as delay coding, binary coding, time coding, and rank order coding. Additionally, they are incorporating Hebbian plasticity and self-organization principles to enhance learning and adaptability.\\n\\nFor further exploration, the \"Pulsed Neural Networks\" book provides insights into implementation issues specific to SNNs.',\n"," 'document': 'f204956e',\n"," 'question': 'How do SNNs differ from previous neural network models?',\n"," 'tags': 'neural-networks',\n"," 'cosine': 0.5959005355834961}"]},"execution_count":95,"metadata":{},"output_type":"execute_result"}],"source":["record = df_sample_llama[0]\n","record"]},{"cell_type":"code","execution_count":98,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T15:07:41.612151Z","iopub.status.busy":"2024-10-08T15:07:41.611662Z","iopub.status.idle":"2024-10-08T15:07:41.618756Z","shell.execute_reply":"2024-10-08T15:07:41.617394Z","shell.execute_reply.started":"2024-10-08T15:07:41.612109Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n","Your task is to analyze the relevance of the generated answer compared to the original answer provided.\n","Based on the relevance and similarity of the generated answer to the original answer, you will classify\n","it as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n","\n","Here is the data for evaluation:\n","\n","Original Answer: **Summary:**\n","\n","Understanding neural networks, including their structure and function, remains a significant challenge. The field has progressed through three key models:\n","\n","* **Perceptron Model:** Can compute any boolean function using a multilayer perceptron with a hidden layer.\n","* **Neuron Model:** An improved version using sigmoid activation, capable of computing any boolean function and approximating continuous functions.\n","* **Spiking Neurons Model:** Incorporates temporal coding to pass information, allowing for more efficient computation than the previous models and a closer fidelity to the human brain.\n","\n","In practice, Spiking Neural Networks (SNNs) show promise, as evidenced by commercial products like SpikeNET. However, challenges arise from the inherent complexity of SNNs, including the need to define information coding methods and emulate biological learning mechanisms.\n","\n","Researchers are exploring various coding techniques to represent information in SNNs, such as delay coding, binary coding, time coding, and rank order coding. Additionally, they are incorporating Hebbian plasticity and self-organization principles to enhance learning and adaptability.\n","\n","For further exploration, the \"Pulsed Neural Networks\" book provides insights into implementation issues specific to SNNs.\n","Generated Question: How do SNNs differ from previous neural network models?\n","Generated Answer: According to the context, SNNs (Spiking Neural Networks) are not mentioned in the provided context. However, the question asks how SNNs differ from previous neural network models. Since SNNs are not mentioned, we cannot provide a direct answer. \n","\n","If the question was rephrased to ask about the differences between previous neural network models, the answer would be that the context mentions various types of neural networks, including:\n","\n","1. Perceptrons: A specific type of neural network introduced by Rosenblatt in 1957.\n","2. Multi-Layered Perceptron (MLP): A type of feed-forward neural network with layers of fully connected nodes.\n","3. Recurrent Neural Networks (RNNs): Neural networks with undirected loops within layers, providing storage capacity.\n","4. Hopfield Network: A type of neural network with a single interconnected layer and binary nodes.\n","5. Restricted Boltzmann Machines (RBMs): Two-layer models with visible and hidden units.\n","6. Convolutional Neural Networks (CNNs): Deep learning models using convolutional filters to process image data.\n","7. Deep Belief Networks (DBNs): Neural networks with undirected connections between some layers.\n","8. Deep Neural Networks (DNNs): Feedforward networks with multiple hidden layers.\n","\n","These neural network models differ in their architecture, training algorithms, and applications.\n","\n","Please analyze the content and context of the generated answer in relation to the original\n","answer and provide your evaluation in parsable JSON without using code blocks:\n","\n","{\n","  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n","  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n","}\n"]}],"source":["prompt = prompt1_template.format(**record)\n","print(prompt)"]},{"cell_type":"code","execution_count":105,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T15:16:33.444692Z","iopub.status.busy":"2024-10-08T15:16:33.443870Z","iopub.status.idle":"2024-10-08T15:16:37.035504Z","shell.execute_reply":"2024-10-08T15:16:37.034357Z","shell.execute_reply.started":"2024-10-08T15:16:33.444642Z"},"trusted":true},"outputs":[],"source":["answer = llm(prompt, model='meta/llama-2-7b-chat-int8')"]},{"cell_type":"code","execution_count":114,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T15:19:56.891823Z","iopub.status.busy":"2024-10-08T15:19:56.891256Z","iopub.status.idle":"2024-10-08T15:29:52.645359Z","shell.execute_reply":"2024-10-08T15:29:52.644186Z","shell.execute_reply.started":"2024-10-08T15:19:56.891764Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 150/150 [09:55<00:00,  3.97s/it]\n"]}],"source":["evaluations_llama = []\n","\n","for record in tqdm(df_sample_llama):\n","    prompt = prompt1_template.format(**record)\n","    evaluation = llm(prompt, model='meta/llama-2-7b-chat-int8')\n","    evaluations_llama.append(evaluation)"]},{"cell_type":"code","execution_count":157,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T15:40:07.238929Z","iopub.status.busy":"2024-10-08T15:40:07.238393Z","iopub.status.idle":"2024-10-08T15:40:07.246011Z","shell.execute_reply":"2024-10-08T15:40:07.244842Z","shell.execute_reply.started":"2024-10-08T15:40:07.238881Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["def process_eval_results(evaluations):\n","    res = []\n","    for i, str_eval in enumerate(evaluations):\n","        match = re.findall(r'\"Relevance\":\\s*\"([^\"]+)\"',str_eval['result']['response'])[0]\n","        res.append(match)\n","    return res"]},{"cell_type":"code","execution_count":159,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T15:40:26.377435Z","iopub.status.busy":"2024-10-08T15:40:26.376965Z","iopub.status.idle":"2024-10-08T15:40:26.383723Z","shell.execute_reply":"2024-10-08T15:40:26.382446Z","shell.execute_reply.started":"2024-10-08T15:40:26.377392Z"},"trusted":true},"outputs":[],"source":["df_evaluations_llama = pd.DataFrame(process_eval_results(evaluations_llama))"]},{"cell_type":"code","execution_count":163,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T15:40:59.646379Z","iopub.status.busy":"2024-10-08T15:40:59.645898Z","iopub.status.idle":"2024-10-08T15:40:59.671828Z","shell.execute_reply":"2024-10-08T15:40:59.670486Z","shell.execute_reply.started":"2024-10-08T15:40:59.646337Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0              \n","RELEVANT           85\n","PARTLY_RELEVANT    54\n","NON_RELEVANT       11\n","Name: count, dtype: int64"]},"execution_count":163,"metadata":{},"output_type":"execute_result"}],"source":["df_evaluations_llama.value_counts()"]},{"cell_type":"code","execution_count":185,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T16:36:55.929735Z","iopub.status.busy":"2024-10-08T16:36:55.929289Z","iopub.status.idle":"2024-10-08T16:44:36.669066Z","shell.execute_reply":"2024-10-08T16:44:36.667845Z","shell.execute_reply.started":"2024-10-08T16:36:55.929692Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f1c626cc8c2b45ab94062c20390197b2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/150 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["evaluations_llama_2 = []\n","\n","for record in tqdm(df_sample_llama):\n","    prompt = prompt2_template.format(**record)\n","    evaluation = llm(prompt, model='meta/llama-2-7b-chat-int8')\n","    evaluations_llama_2.append(evaluation)"]},{"cell_type":"code","execution_count":187,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T16:44:54.838682Z","iopub.status.busy":"2024-10-08T16:44:54.837766Z","iopub.status.idle":"2024-10-08T16:44:54.844591Z","shell.execute_reply":"2024-10-08T16:44:54.843421Z","shell.execute_reply.started":"2024-10-08T16:44:54.838640Z"},"trusted":true},"outputs":[],"source":["df_evaluations_llama_2 = pd.DataFrame(process_eval_results(evaluations_llama_2))"]},{"cell_type":"code","execution_count":188,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T16:45:11.123749Z","iopub.status.busy":"2024-10-08T16:45:11.123300Z","iopub.status.idle":"2024-10-08T16:45:11.135487Z","shell.execute_reply":"2024-10-08T16:45:11.134251Z","shell.execute_reply.started":"2024-10-08T16:45:11.123706Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0              \n","RELEVANT           74\n","PARTLY_RELEVANT    70\n","NON_RELEVANT        6\n","Name: count, dtype: int64"]},"execution_count":188,"metadata":{},"output_type":"execute_result"}],"source":["df_evaluations_llama_2.value_counts()"]},{"cell_type":"code","execution_count":189,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T16:45:25.160725Z","iopub.status.busy":"2024-10-08T16:45:25.159661Z","iopub.status.idle":"2024-10-08T16:45:25.171131Z","shell.execute_reply":"2024-10-08T16:45:25.169763Z","shell.execute_reply.started":"2024-10-08T16:45:25.160659Z"},"trusted":true},"outputs":[],"source":["df_evaluations_llama.to_csv('evaluations_llama-aqa.csv', index=False)\n","df_evaluations_llama_2.to_csv('evaluations_llama-qa.csv', index=False)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30787,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":5}
