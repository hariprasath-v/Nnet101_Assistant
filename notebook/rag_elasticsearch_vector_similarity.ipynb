{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About\n",
    "### Build an LLM-powered RAG using Elasticsearch with vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install OpenAI -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install elasticsearch -qq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade ipywidgets -qq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence_transformers -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import elasticsearch\n",
    "from elasticsearch import Elasticsearch\n",
    "from tqdm.notebook import tqdm, tqdm_notebook \n",
    "\n",
    "import os\n",
    "\n",
    "# Disable tokenizers parallelism\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>q_link</th>\n",
       "      <th>tags</th>\n",
       "      <th>q_question_id</th>\n",
       "      <th>q_is_answered</th>\n",
       "      <th>q_accepted_answer_id</th>\n",
       "      <th>q_view_count</th>\n",
       "      <th>q_answer_count</th>\n",
       "      <th>q_score</th>\n",
       "      <th>q_last_activity_date</th>\n",
       "      <th>q_creation_date</th>\n",
       "      <th>a_score</th>\n",
       "      <th>a_creation_date</th>\n",
       "      <th>a_answer</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to choose the number of hidden layers and ...</td>\n",
       "      <td>https://stats.stackexchange.com/questions/181/...</td>\n",
       "      <td>model-selection|neural-networks</td>\n",
       "      <td>181</td>\n",
       "      <td>True</td>\n",
       "      <td>1097</td>\n",
       "      <td>1145801</td>\n",
       "      <td>10</td>\n",
       "      <td>820</td>\n",
       "      <td>1661947755</td>\n",
       "      <td>1279584902</td>\n",
       "      <td>671</td>\n",
       "      <td>1280715630</td>\n",
       "      <td>I realize this question has been answered, but...</td>\n",
       "      <td>**Network Configuration in Neural Networks**\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What should I do when my neural network doesn&amp;...</td>\n",
       "      <td>https://stats.stackexchange.com/questions/3520...</td>\n",
       "      <td>neural-networks|faq</td>\n",
       "      <td>352036</td>\n",
       "      <td>True</td>\n",
       "      <td>352037</td>\n",
       "      <td>365434</td>\n",
       "      <td>9</td>\n",
       "      <td>368</td>\n",
       "      <td>1701358003</td>\n",
       "      <td>1529367960</td>\n",
       "      <td>455</td>\n",
       "      <td>1529367960</td>\n",
       "      <td>1.  Verify that your code is bug free\\nThere's...</td>\n",
       "      <td>**Key Considerations for Neural Network Develo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What exactly are keys, queries, and values in ...</td>\n",
       "      <td>https://stats.stackexchange.com/questions/4219...</td>\n",
       "      <td>neural-networks|natural-language|attention|mac...</td>\n",
       "      <td>421935</td>\n",
       "      <td>True</td>\n",
       "      <td>424127</td>\n",
       "      <td>261109</td>\n",
       "      <td>11</td>\n",
       "      <td>309</td>\n",
       "      <td>1708928023</td>\n",
       "      <td>1565686855</td>\n",
       "      <td>281</td>\n",
       "      <td>1567068576</td>\n",
       "      <td>The key/value/query formulation of attention i...</td>\n",
       "      <td>In the key/value/query formulation of attentio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is batch size in neural network?</td>\n",
       "      <td>https://stats.stackexchange.com/questions/1535...</td>\n",
       "      <td>neural-networks|python|terminology|keras</td>\n",
       "      <td>153531</td>\n",
       "      <td>True</td>\n",
       "      <td>153535</td>\n",
       "      <td>731148</td>\n",
       "      <td>6</td>\n",
       "      <td>305</td>\n",
       "      <td>1650529048</td>\n",
       "      <td>1432286121</td>\n",
       "      <td>421</td>\n",
       "      <td>1432288067</td>\n",
       "      <td>The batch size defines the number of samples t...</td>\n",
       "      <td>**Summary**\\n\\n**Batch Size**\\n\\nBatch size de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the advantages of ReLU over sigmoid f...</td>\n",
       "      <td>https://stats.stackexchange.com/questions/1262...</td>\n",
       "      <td>machine-learning|neural-networks|sigmoid-curve...</td>\n",
       "      <td>126238</td>\n",
       "      <td>True</td>\n",
       "      <td>126362</td>\n",
       "      <td>290897</td>\n",
       "      <td>9</td>\n",
       "      <td>234</td>\n",
       "      <td>1723495231</td>\n",
       "      <td>1417486429</td>\n",
       "      <td>205</td>\n",
       "      <td>1417567286</td>\n",
       "      <td>Two additional major benefits of ReLUs are spa...</td>\n",
       "      <td>**Summary:**\\n\\nRectified Linear Units (ReLUs)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  How to choose the number of hidden layers and ...   \n",
       "1  What should I do when my neural network doesn&...   \n",
       "2  What exactly are keys, queries, and values in ...   \n",
       "3              What is batch size in neural network?   \n",
       "4  What are the advantages of ReLU over sigmoid f...   \n",
       "\n",
       "                                              q_link  \\\n",
       "0  https://stats.stackexchange.com/questions/181/...   \n",
       "1  https://stats.stackexchange.com/questions/3520...   \n",
       "2  https://stats.stackexchange.com/questions/4219...   \n",
       "3  https://stats.stackexchange.com/questions/1535...   \n",
       "4  https://stats.stackexchange.com/questions/1262...   \n",
       "\n",
       "                                                tags  q_question_id  \\\n",
       "0                    model-selection|neural-networks            181   \n",
       "1                                neural-networks|faq         352036   \n",
       "2  neural-networks|natural-language|attention|mac...         421935   \n",
       "3           neural-networks|python|terminology|keras         153531   \n",
       "4  machine-learning|neural-networks|sigmoid-curve...         126238   \n",
       "\n",
       "   q_is_answered  q_accepted_answer_id  q_view_count  q_answer_count  q_score  \\\n",
       "0           True                  1097       1145801              10      820   \n",
       "1           True                352037        365434               9      368   \n",
       "2           True                424127        261109              11      309   \n",
       "3           True                153535        731148               6      305   \n",
       "4           True                126362        290897               9      234   \n",
       "\n",
       "   q_last_activity_date  q_creation_date  a_score  a_creation_date  \\\n",
       "0            1661947755       1279584902      671       1280715630   \n",
       "1            1701358003       1529367960      455       1529367960   \n",
       "2            1708928023       1565686855      281       1567068576   \n",
       "3            1650529048       1432286121      421       1432288067   \n",
       "4            1723495231       1417486429      205       1417567286   \n",
       "\n",
       "                                            a_answer  \\\n",
       "0  I realize this question has been answered, but...   \n",
       "1  1.  Verify that your code is bug free\\nThere's...   \n",
       "2  The key/value/query formulation of attention i...   \n",
       "3  The batch size defines the number of samples t...   \n",
       "4  Two additional major benefits of ReLUs are spa...   \n",
       "\n",
       "                                              answer  \n",
       "0  **Network Configuration in Neural Networks**\\n...  \n",
       "1  **Key Considerations for Neural Network Develo...  \n",
       "2  In the key/value/query formulation of attentio...  \n",
       "3  **Summary**\\n\\n**Batch Size**\\n\\nBatch size de...  \n",
       "4  **Summary:**\\n\\nRectified Linear Units (ReLUs)...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'https://raw.githubusercontent.com/hariprasath-v/Nnet101_Assistant/refs/heads/main/data/Stackoverflow_data(neural_networks_stats)_pre_processed_Gemini_LLM.csv'\n",
    "data = pd.read_csv(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = data[['question','tags','answer']].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elasticsearch setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200/', request_timeout=60) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\" : \"193089df32da\",\n",
      "  \"cluster_name\" : \"docker-cluster\",\n",
      "  \"cluster_uuid\" : \"sspWQrg0T3yNpltGPAskWA\",\n",
      "  \"version\" : {\n",
      "    \"number\" : \"8.4.3\",\n",
      "    \"build_flavor\" : \"default\",\n",
      "    \"build_type\" : \"docker\",\n",
      "    \"build_hash\" : \"42f05b9372a9a4a470db3b52817899b99a76ee73\",\n",
      "    \"build_date\" : \"2022-10-04T07:17:24.662462378Z\",\n",
      "    \"build_snapshot\" : false,\n",
      "    \"lucene_version\" : \"9.3.0\",\n",
      "    \"minimum_wire_compatibility_version\" : \"7.17.0\",\n",
      "    \"minimum_index_compatibility_version\" : \"7.0.0\"\n",
      "  },\n",
      "  \"tagline\" : \"You Know, for Search\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl localhost:9200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating embedding using sentence transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's embed a sentence and see the dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.encode(\"This is a simple sentence\",show_progress_bar=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How to choose the number of hidden layers and nodes in a feedforward neural network?',\n",
       " 'tags': 'model-selection|neural-networks',\n",
       " 'answer': \"**Network Configuration in Neural Networks**\\n\\n**Standardization**\\nThere is no single standardized method for configuring networks. However, guidelines exist for setting the number and type of network layers, as well as the number of neurons in each layer.\\n\\n**Initial Architecture Setup**\\nBy following specific rules, one can establish a competent network architecture. This involves determining the number and type of neuronal layers and the number of neurons within each layer. This approach provides a foundational architecture but may not be optimal.\\n\\n**Iterative Tuning**\\nOnce the network is initialized, its configuration can be iteratively tuned during training. Ancillary algorithms, such as pruning, can be used to eliminate unnecessary nodes, optimizing the network's size and performance.\\n\\n**Network Layer Types and Sizing**\\nEvery neural network has input, hidden, and output layers.\\n\\n* **Input Layer:** Number of neurons is determined by the number of features in the training data.\\n* **Output Layer:** Number of neurons is determined by the model configuration (regression mode has one node, classification mode uses softmax for multiple classes).\\n* **Hidden Layers:** Number of layers and neurons can be determined empirically, with one hidden layer often being sufficient. Rule of thumb suggests the hidden layer size should be between the input and output layer sizes.\\n\\n**Optimization**\\nPruning techniques can be employed during training to reduce network size and improve performance. This involves identifying and removing nodes that do not significantly impact network performance. Optimizing network configuration can be achieved by initially setting a larger number of neurons and then using pruning to refine the network.\"}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create embedding for answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c182d5e2dc14600a6976fd5474437b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#created the dense vector using the pre-trained model\n",
    "operations = []\n",
    "for doc in tqdm(data_dict):\n",
    "    # Transforming the answer into an embedding using the model\n",
    "    doc[\"answer_vector\"] = model.encode(doc[\"answer\"],show_progress_bar=False,normalize_embeddings=True).tolist()\n",
    "    operations.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: 58\n",
      "tags: 19\n",
      "answer: 1699\n",
      "answer_vector: 384\n"
     ]
    }
   ],
   "source": [
    "for k,v in operations[1].items():\n",
    "    print(f\"{k}: {len(v)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and add index to elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'nnet101'})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dimension=384\n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"answer\": {\"type\": \"text\"},\n",
    "            \"tags\": {\"type\": \"keyword\"},\n",
    "            \"answer_vector\": {\"type\": \"dense_vector\", \"dims\": model_dimension, \"index\": True, \"similarity\": \"cosine\"},\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"nnet101\"\n",
    "\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c02c7acde7614c3e815298a5129aa18f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm_notebook(data_dict):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create query and embed it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = \"What is pooling layer?\"\n",
    "vector_search_term = model.encode(search_term,show_progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_search_term.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"field\": \"answer_vector\",\n",
    "    \"query_vector\": vector_search_term,\n",
    "    \"k\": 5,\n",
    "    \"num_candidates\": 10000, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_index': 'nnet101',\n",
       "  '_id': 'HzieZZIBNZ0du4-0j3JE',\n",
       "  '_score': 0.76976824,\n",
       "  '_source': {'question': 'How to calculate output shape in 3D convolution',\n",
       "   'answer': '**Convolution Layer Summary:**\\n\\nThe convolution formula determines the output size of a convolution layer. It considers the input size, receptive field (kernel) size, stride, and zero padding. In the example, with $W=40$, $F=3$, $S=1$, and $P=0$, the output size is $(38, 62, 62, 8)$.\\n\\n**Pooling Layer Summary:**\\n\\nPooling layers reduce spatial dimensions. By default, they halve each dimension with a receptive field of $(2, 2, 2)$ and a stride of $(2, 2, 2)$. However, if the stride is set to $(1, 1, 1)$, each dimension is reduced by 1 instead. For instance, the tensor $(38, 62, 62, 8)$ would become $(19, 31, 31, 8)$ with a stride of $(2, 2, 2)$ and $(37, 61, 61, 8)$ with a stride of $(1, 1, 1)$.',\n",
       "   'tags': 'machine-learning|neural-networks|convolutional-neural-network'}},\n",
       " {'_index': 'nnet101',\n",
       "  '_id': '8jieZZIBNZ0du4-0jnGQ',\n",
       "  '_score': 0.76280546,\n",
       "  '_source': {'question': 'Difference between pooling and subsampling',\n",
       "   'answer': '**Summary:**\\n\\nPooling layers in convolutional neural networks (CNNs) perform a form of subsampling that reduces the dimensionality of the input data. This process of reducing the size of the data while retaining its essential features is known as subsampling.\\n\\nThe paper \"Gradient-Based Learning Applied to Document Recognition\" by Yann LeCun refers to subsampling as a pooling layer. This suggests that pooling layers can be used to perform subsampling operations in CNNs.\\n\\nIn essence, pooling operations are a type of subsampling that reduce the size of the image while preserving its important characteristics. This makes them a crucial component in CNNs for efficiently extracting features from images.',\n",
       "   'tags': 'neural-networks|convolutional-neural-network|computer-vision'}},\n",
       " {'_index': 'nnet101',\n",
       "  '_id': '7DieZZIBNZ0du4-0jnFv',\n",
       "  '_score': 0.7592964,\n",
       "  '_source': {'question': 'Feature extracted by max pooling vs mean pooling',\n",
       "   'answer': 'Convolutional layers extract features from input data, while pooling layers compress these features to reduce dimensionality. There are two main types of pooling layers: max-pooling and mean-pooling.\\n\\n**Max-pooling** selects the maximum activation value within a block of data, prioritizing the presence of a specific feature in a general area. However, it can lose information about low activations within that block.\\n\\n**Mean-pooling** calculates the average activation value within a block, which can smooth out large activations. It retains some information about low activations but may not capture the presence of specific features as strongly as max-pooling.\\n\\nThe choice between max-pooling and mean-pooling depends on the desired level of feature extraction and the importance of preserving low activation information.',\n",
       "   'tags': 'machine-learning|deep-learning|feature-engineering|computer-vision'}},\n",
       " {'_index': 'nnet101',\n",
       "  '_id': 'tzieZZIBNZ0du4-0iHCZ',\n",
       "  '_score': 0.7557167,\n",
       "  '_source': {'question': 'What is global max pooling layer and what is its advantage over maxpooling layer?',\n",
       "   'answer': '**Summary:**\\n\\nGlobal max pooling is a type of max pooling where the pool size is equal to the input size. Unlike regular max pooling, which produces a smaller output, global max pooling produces an output with the same dimensionality as the input.\\n\\nIn global max pooling, the maximum value across the entire input is extracted, providing a representation that focuses on the most prominent feature. This is useful in applications like natural language processing, where the most important words in a sentence are often indicative of its meaning.\\n\\nIn contrast, regular max pooling divides the input into smaller segments and extracts the maximum value from each segment, reducing the output size. This is more common in computer vision, where spatial information is important and reducing the size of the representation can be beneficial for computational efficiency.',\n",
       "   'tags': 'neural-networks|convolutional-neural-network|pooling'}},\n",
       " {'_index': 'nnet101',\n",
       "  '_id': '9DieZZIBNZ0du4-0iXD8',\n",
       "  '_score': 0.74971545,\n",
       "  '_source': {'question': 'What does kernel size mean?',\n",
       "   'answer': 'Deep neural networks, particularly convolutional neural networks (CNNs), consist of layers defined by the application of filters (kernels) on the input.\\n\\nThese convolutional kernels apply cross-correlation operations, not convolution, to extract features from the input.\\n\\nMax pooling layers use kernels to select the maximum value within a mask, subsampling the input.\\n\\nThe term \"kernel\" in CNNs differs from its usage in support vector machines or regularization networks.\\n\\nInstead, CNN kernels act as feature extractors, identifying patterns and characteristics within the input data.',\n",
       "   'tags': 'machine-learning|neural-networks'}}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = es_client.search(index=index_name, knn=query, source=[\"answer\", \"tags\", \"question\"])\n",
    "res[\"hits\"][\"hits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model-selection|neural-networks'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict[0]['tags']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elasticsearch knn similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_search(search_query):\n",
    "    vector_search_term = model.encode(search_query,show_progress_bar=False)\n",
    "    \n",
    "    knn_query = {\n",
    "        \"field\": \"answer_vector\",\n",
    "        \"query_vector\": vector_search_term,\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000\n",
    "    }\n",
    "    \n",
    " \n",
    "    \n",
    "\n",
    "    response = es_client.search(\n",
    "        index=index_name,\n",
    "\n",
    "        knn=knn_query,\n",
    "        size=5\n",
    "    )\n",
    "    result1 = {k: v for k,v in response[\"hits\"][\"hits\"][0].items() if k != \"_source\"}\n",
    "    result2 = ({k: v for k, v in response[\"hits\"][\"hits\"][0]['_source'].items() if k != 'answer_vector'})\n",
    "    final_result = {**result1, **result2}\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_index': 'nnet101',\n",
       " '_id': 'HzieZZIBNZ0du4-0j3JE',\n",
       " '_score': 0.76976824,\n",
       " 'question': 'How to calculate output shape in 3D convolution',\n",
       " 'tags': 'machine-learning|neural-networks|convolutional-neural-network',\n",
       " 'answer': '**Convolution Layer Summary:**\\n\\nThe convolution formula determines the output size of a convolution layer. It considers the input size, receptive field (kernel) size, stride, and zero padding. In the example, with $W=40$, $F=3$, $S=1$, and $P=0$, the output size is $(38, 62, 62, 8)$.\\n\\n**Pooling Layer Summary:**\\n\\nPooling layers reduce spatial dimensions. By default, they halve each dimension with a receptive field of $(2, 2, 2)$ and a stride of $(2, 2, 2)$. However, if the stride is set to $(1, 1, 1)$, each dimension is reduced by 1 instead. For instance, the tensor $(38, 62, 62, 8)$ would become $(19, 31, 31, 8)$ with a stride of $(2, 2, 2)$ and $(37, 61, 61, 8)$ with a stride of $(1, 1, 1)$.'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_search(search_query='what is pooling layer?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ollamaâ€™s OpenAI compatible API endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1',\n",
    "    api_key='ollama',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to a create prompt using retrieved results and user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"tags: {doc['tags']}\\nquestion: {doc['question']}\\nanswer: {doc['answer']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gemma:2b\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG\n",
    "#### The function retrieves elasticsearch knn similarity results based on the user's query, creates a prompt using those results, and feeds it into the LLM to generate the final response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = knn_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure. Here's a summary  of the term POOKING LAYER:\n",
      "\n",
      "**Pooling layer** is a layer in a neural network that reduces the dimensionality of the input data by taking a subset of the input features and using them to represent the entire input. \n",
      "\n",
      " **Key characteristics of a pooling layer:**\n",
      "\n",
      "* Uses a specific method to extract features from the input.\n",
      "* Is typically followed by a fully connected layer.\n",
      "* Reduces the computational complexity of the model and speeds up training.\n",
      "\n",
      "**Some common pooling layers include:**\n",
      "\n",
      "* **Max pooling:** Takes the maximum value from each input feature and uses it as the output.\n",
      "* **Average pooling:** Takes the average of each input feature and uses it as the output.\n",
      "* **Average pooling with weight factor:** The average value of each feature is weighted by a coefficient before being used as the output. \n",
      "\n",
      "**Benefits of using a pooling layer:**\n",
      "\n",
      "* Reduce overfitting by sharing information from multiple features across all neurons in the layer.\n",
      "* Improve the performance of the neural network by reducing the dimensionality of the input.\n",
      "* Speed up the training of the model.\n",
      "\n",
      "**Applications of pooling layer:**\n",
      "\n",
      "* Image recognition\n",
      "* Natural language processing\n",
      "* Time series analysis\n",
      "* Drug discovery\n",
      "\n",
      "Pooling layer can be used in various layers of a neural network, such as the first layer, hidden layer, and output layer.\n",
      "CPU times: user 5.47 ms, sys: 7.7 ms, total: 13.2 ms\n",
      "Wall time: 36.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(llm('what is pooling layer?'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
